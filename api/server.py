"""
FastAPI —Å–µ—Ä–≤–µ—Ä –¥–ª—è AI Development System
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç REST API –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å AI –∞–≥–µ–Ω—Ç–∞–º–∏
"""
import sys
import os
import logging
import sqlite3
from pathlib import Path
from fastapi import FastAPI, HTTPException, Header, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse, Response, RedirectResponse
from starlette.middleware.base import BaseHTTPMiddleware
from pydantic import BaseModel, Field, EmailStr
from typing import Literal, Optional, List, Dict, Any, Union
from datetime import datetime, timedelta
import uvicorn
from fastapi.responses import StreamingResponse
import asyncio
import json
import time
import csv
import io
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.starlette import StarletteIntegration

# Initialize Sentry for error tracking
SENTRY_DSN = os.getenv("SENTRY_DSN")
if SENTRY_DSN:
    sentry_sdk.init(
        dsn=SENTRY_DSN,
        integrations=[
            StarletteIntegration(transaction_style="endpoint"),
            FastApiIntegration(transaction_style="endpoint"),
        ],
        traces_sample_rate=0.1,  # 10% of transactions for performance monitoring
        environment=os.getenv("ENVIRONMENT", "development"),
        release=os.getenv("RELEASE_VERSION", "1.0.0")
    )

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent))
# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ agents
sys.path.append(str(Path(__file__).parent.parent / "agents"))

from ai_router import AIRouter
from database import get_db
from ranking_collector import RankingCollector
from auth import hash_password, verify_password, create_jwt_token, verify_jwt_token as verify_jwt
from rate_limiter import get_rate_limiter
from csrf_protection import get_csrf_protection
from oauth_providers import oauth_manager
from two_factor_auth import TwoFactorAuth
from monitoring import metrics_collector, alert_manager, request_monitor, system_monitor, AlertSeverity

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI(
    title="AI Development System API",
    description="REST API –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è AI –∞–≥–µ–Ω—Ç–∞–º–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
    version="1.0.0"
)

# CORS –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
# –í production –¥–æ–º–µ–Ω—ã —á–∏—Ç–∞—é—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è CORS_ORIGINS
# –§–æ—Ä–º–∞—Ç: CORS_ORIGINS=https://app.example.com,https://www.example.com
DEFAULT_ORIGINS = [
    "http://localhost:3000",
    "http://localhost:3001",
    "http://localhost:3002",
    "http://localhost:5173",  # Vite dev server
]

# –ü–æ–ª—É—á–∞–µ–º production –¥–æ–º–µ–Ω—ã –∏–∑ env –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
CORS_ORIGINS_ENV = os.getenv("CORS_ORIGINS", "")
if CORS_ORIGINS_ENV:
    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∑–∞–ø—è—Ç–æ–π –∏ –æ—á–∏—â–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    production_origins = [origin.strip() for origin in CORS_ORIGINS_ENV.split(",") if origin.strip()]
    ALLOWED_ORIGINS = DEFAULT_ORIGINS + production_origins
else:
    ALLOWED_ORIGINS = DEFAULT_ORIGINS

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["Content-Type", "Authorization"],
)

# Gzip compression middleware –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
app.add_middleware(GZipMiddleware, minimum_size=1000)  # –°–∂–∏–º–∞–µ–º –æ—Ç–≤–µ—Ç—ã > 1KB

# CSP Headers Middleware –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç XSS
class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)

        # Content Security Policy
        response.headers["Content-Security-Policy"] = (
            "default-src 'self'; "
            "script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdn.jsdelivr.net; "
            "style-src 'self' 'unsafe-inline' https://fonts.googleapis.com; "
            "font-src 'self' https://fonts.gstatic.com; "
            "img-src 'self' data: https: blob:; "
            "connect-src 'self' http://localhost:* ws://localhost:* https://api.openai.com https://api.anthropic.com; "
            "frame-ancestors 'none'; "
            "form-action 'self';"
        )

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ security headers
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["X-XSS-Protection"] = "1; mode=block"
        response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
        response.headers["Permissions-Policy"] = "geolocation=(), microphone=(), camera=()"

        # HSTS –¥–ª—è production (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏ HTTPS)
        # response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"

        return response

app.add_middleware(SecurityHeadersMiddleware)

# API Version Middleware - –¥–æ–±–∞–≤–ª—è–µ—Ç –≤–µ—Ä—Å–∏—é API –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤
class APIVersionMiddleware(BaseHTTPMiddleware):
    """Middleware –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤–µ—Ä—Å–∏–∏ API –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤"""
    
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        response.headers["X-API-Version"] = app.version
        response.headers["X-API-Server"] = "AI Assistant Platform"
        return response

app.add_middleware(APIVersionMiddleware)

# ============================================
# Monitoring Middleware
# ============================================

class MonitoringMiddleware(BaseHTTPMiddleware):
    """Middleware –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""

    async def dispatch(self, request: Request, call_next):
        # Start timer
        start_time = time.time()

        # Process request
        try:
            response = await call_next(request)

            # Record metrics
            duration = time.time() - start_time
            request_monitor.record_request(
                method=request.method,
                path=request.url.path,
                status_code=response.status_code,
                duration=duration
            )

            # Add timing header
            response.headers["X-Response-Time"] = f"{duration:.3f}"

            # Alert on slow requests
            if duration > 10:  # More than 10 seconds
                alert_manager.create_alert(
                    severity=AlertSeverity.WARNING,
                    title="Slow Request Detected",
                    message=f"Request to {request.url.path} took {duration:.2f} seconds",
                    source="MonitoringMiddleware",
                    metadata={
                        "method": request.method,
                        "path": request.url.path,
                        "duration": duration
                    }
                )

            return response

        except Exception as e:
            # Record error
            duration = time.time() - start_time
            request_monitor.record_request(
                method=request.method,
                path=request.url.path,
                status_code=500,
                duration=duration
            )

            # Report to Sentry
            if SENTRY_DSN:
                sentry_sdk.capture_exception(e)

            # Create alert for critical errors
            alert_manager.create_alert(
                severity=AlertSeverity.ERROR,
                title="Request Failed",
                message=str(e),
                source="MonitoringMiddleware",
                metadata={
                    "method": request.method,
                    "path": request.url.path,
                    "error": str(e)
                }
            )

            raise

app.add_middleware(MonitoringMiddleware)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI Router
router = AIRouter()

# ============================================
# Include Routers
# ============================================

# Import and include chat router
try:
    from api.routers import chat_router
    app.include_router(chat_router.router)
    logger.info("Chat router loaded successfully")
except ImportError as e:
    logger.warning(f"Could not load chat router: {e}")

# Import and include credit router
try:
    from api.routers import credit_router
    app.include_router(credit_router.router)
    logger.info("Credit router loaded successfully")
except ImportError as e:
    logger.warning(f"Could not load credit router: {e}")

# ============================================
# Startup and Shutdown Events
# ============================================

@app.on_event("startup")
async def startup_event():
    """Initialize services on startup"""
    logger.info("Starting AI Development System API")

    # Start workflow scheduler for scheduled triggers
    try:
        import sys
        sys.path.append(str(Path(__file__).parent.parent / "agents"))
        from workflow_scheduler import start_scheduler
        start_scheduler()
        logger.info("Workflow scheduler started successfully")
    except Exception as e:
        logger.error(f"Failed to start workflow scheduler: {e}")

    # Start system monitoring
    asyncio.create_task(system_monitor.start(interval=60))

    # Initialize alert channels if configured
    if os.getenv("SMTP_HOST"):
        from monitoring import EmailNotificationChannel
        email_channel = EmailNotificationChannel(
            smtp_host=os.getenv("SMTP_HOST"),
            smtp_port=int(os.getenv("SMTP_PORT", 587)),
            username=os.getenv("SMTP_USERNAME"),
            password=os.getenv("SMTP_PASSWORD"),
            to_emails=os.getenv("ALERT_EMAILS", "").split(",")
        )
        alert_manager.add_notification_channel(email_channel)

    if os.getenv("WEBHOOK_URL"):
        from monitoring import WebhookNotificationChannel
        webhook_channel = WebhookNotificationChannel(os.getenv("WEBHOOK_URL"))
        alert_manager.add_notification_channel(webhook_channel)

    logger.info("API startup complete")

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    logger.info("Shutting down AI Development System API")

    # Stop workflow scheduler
    try:
        from workflow_scheduler import stop_scheduler
        stop_scheduler()
        logger.info("Workflow scheduler stopped")
    except Exception as e:
        logger.error(f"Error stopping workflow scheduler: {e}")

    system_monitor.stop()

# ============================================
# Pydantic Models (—Å—Ö–µ–º—ã –¥–∞–Ω–Ω—ã—Ö)
# ============================================

class ChatRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –∫ AI –º–æ–¥–µ–ª–∏"""
    prompt: str = Field(..., description="–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞", min_length=1)
    task_type: Literal['architecture', 'code', 'review', 'test', 'devops', 'research', 'chat', 'general'] = Field(
        default='chat',
        description="–¢–∏–ø –∑–∞–¥–∞—á–∏"
    )
    complexity: int = Field(default=5, ge=1, le=10, description="–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ (1-10)")
    budget: Literal['free', 'cheap', 'medium', 'expensive'] = Field(
        default='cheap',
        description="–ë—é–¥–∂–µ—Ç–Ω—ã–π –ª–∏–º–∏—Ç"
    )
    session_id: Optional[str] = None

class ChatResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –æ—Ç AI"""
    response: str
    model: str
    tokens: int
    cost: float
    error: bool = False

class ProjectRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
    idea: str = Field(..., description="–û–ø–∏—Å–∞–Ω–∏–µ –∏–¥–µ–∏ –ø—Ä–æ–µ–∫—Ç–∞", min_length=10)
    budget: Literal['free', 'cheap', 'medium', 'premium'] = Field(
        default='medium',
        description="–ë—é–¥–∂–µ—Ç–Ω—ã–π –ª–∏–º–∏—Ç"
    )

class ProjectResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞"""
    project_id: str
    architecture: dict
    code: dict
    review: dict
    total_cost: float
    status: str

class StatsResponse(BaseModel):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    calls: int
    tokens: int
    cost: float
    avg_cost_per_call: float
    by_model: dict
    available_models: dict

class HealthResponse(BaseModel):
    """–°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    status: str
    services: dict
    router_stats: dict

class HistoryResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π –∑–∞–ø—Ä–æ—Å–æ–≤"""
    total: int
    items: list
    page: int
    limit: int

class HistoryStatsResponse(BaseModel):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏"""
    general: dict
    by_model: list
    by_task: list
    by_date: list

# ============================================
# Authentication Models
# ============================================

class RegisterRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    email: EmailStr
    password: str = Field(min_length=8, description="Password (min 8 characters)")

class LoginRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –≤—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É"""
    email: EmailStr
    password: str

class UserInfo(BaseModel):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
    id: int
    email: str
    created_at: str
    last_login_at: Optional[str] = None

class AuthResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å —Ç–æ–∫–µ–Ω–æ–º –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    token: str
    user: UserInfo

# ============================================
# Projects Management Models
# ============================================

class ProjectCreate(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
    name: str = Field(..., min_length=1, max_length=100, description="–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞")
    description: Optional[str] = Field(None, max_length=500, description="–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞")

class ProjectUpdate(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
    name: Optional[str] = Field(None, min_length=1, max_length=100, description="–ù–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ")
    description: Optional[str] = Field(None, max_length=500, description="–ù–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ")

class ProjectDetail(BaseModel):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ"""
    id: int
    user_id: int
    name: str
    description: Optional[str]
    created_at: str
    database_count: int = 0

# ============================================
# Databases Management Models
# ============================================

class ColumnDefinition(BaseModel):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å—Ö–µ–º–µ"""
    name: str = Field(..., min_length=1, max_length=50, description="–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏")
    type: Literal['text', 'number', 'boolean', 'date', 'select'] = Field(..., description="–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö")
    required: bool = Field(default=False, description="–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ")
    options: Optional[List[str]] = Field(None, description="–û–ø—Ü–∏–∏ –¥–ª—è select type")
    min_length: Optional[int] = Field(None, description="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è text")
    max_length: Optional[int] = Field(None, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è text")
    min_value: Optional[float] = Field(None, description="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è number")
    max_value: Optional[float] = Field(None, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è number")

class DatabaseSchema(BaseModel):
    """–°—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    columns: List[ColumnDefinition] = Field(..., description="–°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫", min_length=1)

class DatabaseCreate(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    project_id: int = Field(..., gt=0, description="ID –ø—Ä–æ–µ–∫—Ç–∞")
    name: str = Field(..., min_length=1, max_length=100, description="–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    description: Optional[str] = Field(None, description="–û–ø–∏—Å–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    schema: Union[DatabaseSchema, List[Dict[str, Any]]] = Field(..., description="–°—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")

    class Config:
        protected_namespaces = ()

class DatabaseResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    id: int
    project_id: int
    name: str
    schema: DatabaseSchema
    record_count: int = 0
    created_at: str

    class Config:
        protected_namespaces = ()

class RecordCreate(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
    database_id: Optional[int] = Field(None, description="ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è /api/records endpoint)")
    data: Dict[str, Any] = Field(..., description="–î–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏")

class RecordUpdate(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
    data: Dict[str, Any] = Field(..., description="–ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏")

class RecordResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞–ø–∏—Å–∏"""
    id: int
    database_id: int
    data: Dict[str, Any]
    created_at: str
    updated_at: str


# ============================================
# Workflow Models
# ============================================

class WorkflowTrigger(BaseModel):
    """–¢—Ä–∏–≥–≥–µ—Ä workflow"""
    type: Literal['manual', 'schedule', 'webhook', 'email_received', 'record_created']
    config: Dict[str, Any] = {}


class WorkflowAction(BaseModel):
    """–î–µ–π—Å—Ç–≤–∏–µ workflow"""
    type: str  # send_email, create_record, call_webhook, etc.
    config: Dict[str, Any]


class WorkflowCreate(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ workflow"""
    name: str = Field(..., min_length=1, max_length=100)
    trigger: WorkflowTrigger
    actions: List[WorkflowAction] = Field(..., min_items=1)
    enabled: bool = True


class WorkflowUpdate(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ workflow"""
    name: Optional[str] = Field(None, min_length=1, max_length=100)
    trigger: Optional[WorkflowTrigger] = None
    actions: Optional[List[WorkflowAction]] = Field(None, min_items=1)
    enabled: Optional[bool] = None


class WorkflowResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ workflow"""
    id: int
    user_id: int
    name: str
    trigger: WorkflowTrigger
    actions: List[WorkflowAction]
    enabled: bool
    created_at: str


class ExecutionResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ workflow"""
    id: int
    workflow_id: int
    status: str
    result: Optional[Dict[str, Any]]
    error: Optional[str]
    executed_at: str


# === INTEGRATIONS MODELS ===

class IntegrationInfo(BaseModel):
    """Information about an integration"""
    type: Literal['gmail', 'google_drive', 'telegram']
    name: str
    description: str
    icon: str
    requires_oauth: bool
    status: Literal['connected', 'disconnected', 'error']
    last_sync: Optional[str] = None


class ConnectRequest(BaseModel):
    """Request to connect an integration"""
    integration_type: str
    # For Telegram (bot token and chat_id)
    bot_token: Optional[str] = None
    chat_id: Optional[str] = None


# ============================================
# API Endpoints
# ============================================

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    return {
        "status": "running",
        "message": "AI Development System API",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ AI
    
    –ü—Ä–∏–º–µ—Ä—ã:
```json
    {
        "prompt": "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –º–∞—Å—Å–∏–≤–∞",
        "task_type": "code",
        "complexity": 3,
        "budget": "free"
    }
```
    """
    try:
        result = router.route(
            prompt=request.prompt,
            task_type=request.task_type,
            complexity=request.complexity,
            budget=request.budget,
            session_id=request.session_id
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        db = get_db()
        db.add_request(
            prompt=request.prompt,
            response=result['response'],
            model=result['model'],
            task_type=request.task_type,
            complexity=request.complexity,
            budget=request.budget,
            tokens=result.get('tokens', 0),
            cost=result.get('cost', 0.0),
            error=result.get('error', False)
        )
        
        return ChatResponse(**result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/project", response_model=ProjectResponse)
async def create_project(request: ProjectRequest):
    """
    –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –∏–∑ –∏–¥–µ–∏
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª:
    1. –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (Claude/GPT-4)
    2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ (GPT-4/DeepSeek)
    3. –ö–æ–¥-—Ä–µ–≤—å—é (Gemini/DeepSeek)
    
    –ü—Ä–∏–º–µ—Ä—ã:
```json
    {
        "idea": "CRM —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–µ–Ω–¥–∏–Ω–≥–æ–≤—ã–º–∏ –∞–≤—Ç–æ–º–∞—Ç–∞–º–∏",
        "budget": "medium"
    }
```
    """
    try:
        # 1. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        print(f"üìê Creating architecture for: {request.idea}")
        architecture = router.route(
            prompt=f"""Create detailed software architecture for this project:

Project: {request.idea}

Include:
1. Tech stack recommendations
2. System architecture (frontend, backend, database)
3. API endpoints structure
4. Database schema
5. Key components and their responsibilities

Return in structured format.""",
            task_type='architecture',
            complexity=8,
            budget=request.budget
        )
        
        # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞
        print(f"üíª Generating code...")
        code = router.route(
            prompt=f"""Based on this architecture, generate production-ready starter code:

ARCHITECTURE:
{architecture['response']}

Generate:
1. Main application structure
2. Core API endpoints (at least 3)
3. Database models
4. Configuration files

Use TypeScript for frontend, Python/FastAPI for backend.""",
            task_type='code',
            complexity=7,
            budget=request.budget
        )
        
        # 3. –ö–æ–¥-—Ä–µ–≤—å—é
        print(f"üîç Running code review...")
        review = router.route(
            prompt=f"""Review this generated code:

CODE:
{code['response'][:2000]}...

Check for:
1. Security issues
2. Best practices
3. Performance concerns
4. Missing error handling

Provide brief summary with score (0-100).""",
            task_type='review',
            complexity=5,
            budget='cheap'
        )
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        project_id = f"proj_{hash(request.idea) % 100000:05d}"
        total_cost = (
            architecture.get('cost', 0) + 
            code.get('cost', 0) + 
            review.get('cost', 0)
        )
        
        return ProjectResponse(
            project_id=project_id,
            architecture=architecture,
            code=code,
            review=review,
            total_cost=total_cost,
            status="completed"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/stats", response_model=StatsResponse)
async def get_stats():
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è AI –º–æ–¥–µ–ª–µ–π
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
    - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
    - –ó–∞—Ç—Ä–∞—á–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    - –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π
    """
    try:
        stats = router.get_stats()
        return StatsResponse(**stats)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/health", response_model=HealthResponse)
async def health_check():
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
    - –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å AI –º–æ–¥–µ–ª–µ–π
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    - –û–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
    - –í–µ—Ä—Å–∏—é API
    - –°—Ç–∞—Ç—É—Å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        available = router._get_available_models()
        stats = router.get_stats()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        db_status = "healthy"
        try:
            db = get_db()
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
            with sqlite3.connect(db.db_path) as conn:
                conn.execute("SELECT 1").fetchone()
        except Exception as e:
            db_status = f"error: {str(e)}"
            logger.error(f"Database health check failed: {e}")
        
        return HealthResponse(
            status="healthy",
            services={
                "anthropic": available['claude'],
                "openai": available['openai'],
                "openrouter": available['openrouter'],
                "gemini": available['gemini'],
                "ollama": available['ollama'],
                "database": db_status
            },
            router_stats={
                "total_calls": stats['calls'],
                "total_cost": stats['cost'],
                "api_version": app.version
            }
        )
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models")
async def list_models():
    """
    –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –∏—Ö —Å—Ç–∞—Ç—É—Å
    """
    available = router._get_available_models()
    
    models_info = {
        "claude": {
            "name": "Claude Sonnet 4.5",
            "available": available['claude'],
            "use_cases": ["architecture", "research", "complex_code"],
            "cost": "$$$ (Premium)"
        },
        "openai": {
            "name": "GPT-4 Turbo",
            "available": available['openai'],
            "use_cases": ["code", "test", "general"],
            "cost": "$$ (Medium)"
        },
        "openrouter": {
            "name": "DeepSeek V3",
            "available": available['openrouter'],
            "use_cases": ["code", "devops", "review"],
            "cost": "$ (Cheap)"
        },
        "gemini": {
            "name": "Gemini 2.0 Flash",
            "available": available['gemini'],
            "use_cases": ["review", "quick_code", "validation"],
            "cost": "FREE"
        },
        "ollama": {
            "name": "Ollama (Local)",
            "available": available['ollama'],
            "use_cases": ["offline", "private", "unlimited"],
            "cost": "FREE (Local)"
        }
    }
    
    return models_info


# ============================================
# Monitoring Endpoints
# ============================================

@app.get("/api/metrics")
async def get_metrics(
    name: Optional[str] = None,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã

    Args:
    - name: –ò–º—è –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    - start_time: –ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞ (ISO format)
    - end_time: –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞ (ISO format)

    Returns:
    - metrics: –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫
    - summary: –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    """
    start = datetime.fromisoformat(start_time) if start_time else None
    end = datetime.fromisoformat(end_time) if end_time else None

    metrics = metrics_collector.get_metrics(name, start, end)
    summary = metrics_collector.get_summary()

    return {
        "metrics": [m.to_dict() for m in metrics[-1000:]],  # Last 1000 metrics
        "summary": summary
    }


@app.get("/api/alerts")
async def get_alerts(
    active_only: bool = False,
    limit: int = 100
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∞–ª–µ—Ä—Ç—ã —Å–∏—Å—Ç–µ–º—ã

    Args:
    - active_only: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ –∞–ª–µ—Ä—Ç—ã
    - limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–ª–µ—Ä—Ç–æ–≤

    Returns:
    - alerts: –°–ø–∏—Å–æ–∫ –∞–ª–µ—Ä—Ç–æ–≤
    - active_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–ª–µ—Ä—Ç–æ–≤
    """
    if active_only:
        alerts = alert_manager.get_active_alerts()
    else:
        alerts = alert_manager.get_alert_history(limit)

    return {
        "alerts": [a.to_dict() for a in alerts],
        "active_count": len(alert_manager.get_active_alerts())
    }


@app.post("/api/alerts/{alert_id}/resolve")
async def resolve_alert(alert_id: str):
    """
    –û—Ç–º–µ—Ç–∏—Ç—å –∞–ª–µ—Ä—Ç –∫–∞–∫ —Ä–µ—à–µ–Ω–Ω—ã–π

    Args:
    - alert_id: ID –∞–ª–µ—Ä—Ç–∞

    Returns:
    - resolved: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
    """
    alert_manager.resolve_alert(alert_id)
    return {"resolved": True}


@app.get("/api/system-status")
async def get_system_status():
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã

    Returns:
    - health: –°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è
    - metrics: –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    - alerts: –ê–∫—Ç–∏–≤–Ω—ã–µ –∞–ª–µ—Ä—Ç—ã
    - performance: –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    """
    # Get system metrics
    summary = metrics_collector.get_summary()

    # Calculate average response time
    request_durations = summary.get("histograms", {}).get("http_request_duration_seconds", {})
    avg_response_time = request_durations.get("mean", 0) if request_durations else 0

    # Get error rates
    total_requests = summary.get("counters", {}).get("http_requests_total", 0)
    error_5xx = summary.get("counters", {}).get("http_errors_total{type=5xx}", 0)
    error_4xx = summary.get("counters", {}).get("http_errors_total{type=4xx}", 0)

    error_rate = ((error_5xx + error_4xx) / total_requests * 100) if total_requests > 0 else 0

    # Get system resources
    cpu_percent = summary.get("gauges", {}).get("system_cpu_percent", 0)
    memory_percent = summary.get("gauges", {}).get("system_memory_percent", 0)
    disk_percent = summary.get("gauges", {}).get("system_disk_percent", 0)

    # Determine health status
    health_status = "healthy"
    if error_rate > 10 or cpu_percent > 90 or memory_percent > 90:
        health_status = "degraded"
    if error_rate > 25 or cpu_percent > 95 or memory_percent > 95:
        health_status = "critical"

    return {
        "health": health_status,
        "timestamp": datetime.utcnow().isoformat(),
        "metrics": {
            "requests": {
                "total": total_requests,
                "errors_5xx": error_5xx,
                "errors_4xx": error_4xx,
                "error_rate": f"{error_rate:.2f}%"
            },
            "performance": {
                "avg_response_time": f"{avg_response_time:.3f}s",
                "p95_response_time": f"{request_durations.get('p95', 0):.3f}s" if request_durations else "0.000s",
                "p99_response_time": f"{request_durations.get('p99', 0):.3f}s" if request_durations else "0.000s"
            },
            "resources": {
                "cpu_percent": cpu_percent,
                "memory_percent": memory_percent,
                "disk_percent": disk_percent,
                "process_count": summary.get("gauges", {}).get("system_process_count", 0)
            }
        },
        "alerts": {
            "active": len(alert_manager.get_active_alerts()),
            "recent": [a.to_dict() for a in alert_manager.get_active_alerts()[:5]]
        }
    }


@app.get("/api/history", response_model=HistoryResponse)
async def get_history(
    limit: int = 50,
    offset: int = 0,
    model: Optional[str] = None,
    task_type: Optional[str] = None,
    search: Optional[str] = None
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ AI
    
    Parameters:
    - limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π (max 100)
    - offset: —Å–º–µ—â–µ–Ω–∏–µ –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
    - model: —Ñ–∏–ª—å—Ç—Ä –ø–æ –º–æ–¥–µ–ª–∏
    - task_type: —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
    - search: –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É
    """
    try:
        db = get_db()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π limit
        limit = min(limit, 100)
        
        items = db.get_history(
            limit=limit,
            offset=offset,
            model=model,
            task_type=task_type,
            search=search
        )
        
        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (–¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏)
        # –£–ø—Ä–æ—â–µ–Ω–Ω–æ - –±–µ—Ä–µ–º –∏–∑ —Ç–µ–∫—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        total = len(items) + offset
        
        return HistoryResponse(
            total=total,
            items=items,
            page=offset // limit + 1 if limit > 0 else 1,
            limit=limit
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/history/stats", response_model=HistoryStatsResponse)
async def get_history_stats():
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –û–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –º–æ–¥–µ–ª—è–º
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞—Ç–∞–º (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π)
    """
    try:
        db = get_db()
        stats = db.get_stats()
        return HistoryStatsResponse(**stats)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/history/export")
async def export_history(
    format: str = "json",
    model: Optional[str] = None,
    task_type: Optional[str] = None
):
    """
    –≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –≤ —Ñ–∞–π–ª
    
    Parameters:
    - format: json –∏–ª–∏ csv
    - model: —Ñ–∏–ª—å—Ç—Ä –ø–æ –º–æ–¥–µ–ª–∏
    - task_type: —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
    """
    try:
        import tempfile
        from fastapi.responses import FileResponse
        
        db = get_db()
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        suffix = ".json" if format == "json" else ".csv"
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
        
        # –≠–∫—Å–ø–æ—Ä—Ç
        if format == "json":
            count = db.export_to_json(
                temp_file.name,
                model=model,
                task_type=task_type
            )
        else:
            count = db.export_to_csv(
                temp_file.name,
                model=model,
                task_type=task_type
            )
        
        filename = f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}{suffix}"
        
        return FileResponse(
            temp_file.name,
            media_type="application/octet-stream",
            filename=filename
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# AI Models Ranking Endpoints
# ============================================

@app.get("/api/rankings")
async def get_rankings():
    """
    –ü–æ–ª—É—á–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–π—Ç–∏–Ω–≥–∏ –≤—Å–µ—Ö AI –º–æ–¥–µ–ª–µ–π

    Returns:
        Dict —Å —É—Å–ø–µ—Ö–æ–º, —Å–ø–∏—Å–∫–æ–º –º–æ–¥–µ–ª–µ–π —Å —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏ –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º
    """
    try:
        db = get_db()
        rankings = db.get_all_rankings()
        return {
            "success": True,
            "rankings": rankings,
            "count": len(rankings)
        }
    except Exception as e:
        logger.error(f"Rankings error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/rankings/{category}")
async def get_rankings_by_category(category: str, limit: int = 3):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–π—Ç–∏–Ω–≥–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    
    Parameters:
    - category: reasoning, coding, vision, chat, agents, translation, local
    - limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π (default: 3)
    """
    try:
        db = get_db()
        rankings = db.get_rankings_by_category(category, limit)
        return {"category": category, "models": rankings}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/rankings/update")
async def update_rankings():
    """
    –û–±–Ω–æ–≤–∏—Ç—å —Ä–µ–π—Ç–∏–Ω–≥–∏ (–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö)
    
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    """
    try:
        collector = RankingCollector()
        stats = collector.collect_all_rankings()
        
        total = sum(stats.values())
        
        return {
            "success": True,
            "total_updated": total,
            "by_category": stats,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/rankings/sources")
async def get_trusted_sources():
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        db = get_db()
        sources = db.get_trusted_sources()
        return {"sources": sources, "count": len(sources)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# Streaming Chat Endpoint
# ============================================

async def stream_chat_response(prompt: str, task_type: str, complexity: int, budget: str, session_id: str = None):
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ –æ—Ç–≤–µ—Ç–∞
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç —Ä–æ—É—Ç–µ—Ä–∞
        result = router.route(
            prompt=prompt,
            task_type=task_type,
            complexity=complexity,
            budget=budget,
            session_id=session_id
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        metadata = {
            'type': 'metadata',
            'model': result['model'],
            'cost': result['cost'],
            'context_used': result.get('context_used', False),
            'context_length': result.get('context_length', 0)
        }
        yield f"data: {json.dumps(metadata)}\n\n"
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º streaming - —Ä–∞–∑–±–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏
        response_text = result['response']
        words = response_text.split()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –ø–æ —á–∞—Å—Ç—è–º
        for i, word in enumerate(words):
            chunk = word + (' ' if i < len(words) - 1 else '')
            yield f"data: {json.dumps({'type': 'content', 'chunk': chunk})}\n\n"
            await asyncio.sleep(0.05)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        yield f"data: {json.dumps({'type': 'done', 'tokens': result['tokens']})}\n\n"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        db = get_db()
        db.add_request(
            prompt=prompt,
            response=response_text,
            model=result['model'],
            task_type=task_type,
            complexity=complexity,
            budget=budget,
            tokens=result.get('tokens', 0),
            cost=result.get('cost', 0.0),
            error=result.get('error', False)
        )
        
    except Exception as e:
        yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"


@app.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    –ü–æ—Ç–æ–∫–æ–≤—ã–π —á–∞—Ç —Å AI (Server-Sent Events)
    """
    return StreamingResponse(
        stream_chat_response(
            prompt=request.prompt,
            task_type=request.task_type,
            complexity=request.complexity,
            budget=request.budget,
            session_id=request.session_id
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

# ============================================
# Authentication Endpoints
# ============================================

@app.post("/api/auth/register", response_model=AuthResponse)
async def register(request: RegisterRequest, client_request: Request):
    """
    –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Parameters:
    - email: Email –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    - password: –ü–∞—Ä–æ–ª—å (–º–∏–Ω–∏–º—É–º 8 —Å–∏–º–≤–æ–ª–æ–≤)

    Returns:
    - token: JWT —Ç–æ–∫–µ–Ω
    - user: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º rate limiting
    client_ip = client_request.client.host if client_request.client else "unknown"
    rate_limiter = get_rate_limiter()

    if not rate_limiter.check_rate_limit(f"auth_register:{client_ip}", tier="anonymous"):
        raise HTTPException(
            status_code=429,
            detail="Too many registration attempts. Please try again later."
        )

    try:
        db = get_db()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        existing = db.get_user_by_email(request.email)
        if existing:
            raise HTTPException(status_code=400, detail="Email already registered")

        # –•—ç—à–∏—Ä—É–µ–º –ø–∞—Ä–æ–ª—å
        password_hash = hash_password(request.password)

        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id = db.create_user(request.email, password_hash)

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user = db.get_user_by_email(request.email)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω
        token = create_jwt_token(user_id, request.email)

        # –°–æ–∑–¥–∞–µ–º response —Å cookie
        response = JSONResponse(content={
            "token": token,  # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            "user": {
                "id": user['id'],
                "email": user['email'],
                "created_at": user['created_at'].isoformat() if isinstance(user['created_at'], datetime) else user['created_at']
            },
            "message": "Registration successful"
        })

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º httpOnly cookie
        secure_cookie = os.getenv("ENVIRONMENT", "development").lower() == "production"
        response.set_cookie(
            key="auth_token",
            value=token,
            httponly=True,  # –ó–∞—â–∏—Ç–∞ –æ—Ç XSS
            secure=secure_cookie,  # True –≤ production —Å HTTPS
            samesite="lax",  # –ó–∞—â–∏—Ç–∞ –æ—Ç CSRF
            max_age=86400,  # 24 —á–∞—Å–∞
            path="/"
        )

        return response
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/auth/login", response_model=AuthResponse)
async def login(request: LoginRequest, client_request: Request):
    """
    –í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É

    Parameters:
    - email: Email –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    - password: –ü–∞—Ä–æ–ª—å

    Returns:
    - token: JWT —Ç–æ–∫–µ–Ω
    - user: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º rate limiting (–±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –¥–ª—è login)
    client_ip = client_request.client.host if client_request.client else "unknown"
    rate_limiter = get_rate_limiter()

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é IP + email –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç brute force –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤
    if not rate_limiter.check_rate_limit(f"auth_login:{client_ip}:{request.email}", tier="anonymous"):
        raise HTTPException(
            status_code=429,
            detail="Too many login attempts. Please try again later."
        )

    try:
        db = get_db()

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user = db.get_user_by_email(request.email)
        if not user:
            raise HTTPException(status_code=401, detail="Invalid credentials")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–æ–ª—å
        if not verify_password(request.password, user['password_hash']):
            raise HTTPException(status_code=401, detail="Invalid credentials")

        # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤—Ö–æ–¥–∞
        db.update_user_last_login(user['id'])

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω
        token = create_jwt_token(user['id'], user['email'])

        # –°–æ–∑–¥–∞–µ–º response —Å cookie
        response = JSONResponse(content={
            "token": token,  # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            "user": {
                "id": user['id'],
                "email": user['email'],
                "created_at": user['created_at'].isoformat() if isinstance(user['created_at'], datetime) else user['created_at']
            },
            "message": "Login successful"
        })

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º httpOnly cookie
        secure_cookie = os.getenv("ENVIRONMENT", "development").lower() == "production"
        response.set_cookie(
            key="auth_token",
            value=token,
            httponly=True,  # –ó–∞—â–∏—Ç–∞ –æ—Ç XSS
            secure=secure_cookie,  # True –≤ production —Å HTTPS
            samesite="lax",  # –ó–∞—â–∏—Ç–∞ –æ—Ç CSRF
            max_age=86400,  # 24 —á–∞—Å–∞
            path="/"
        )

        return response
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/auth/refresh")
async def refresh_token(authorization: str = Header(None)):
    """
    –û–±–Ω–æ–≤–∏—Ç—å JWT —Ç–æ–∫–µ–Ω (refresh token endpoint)
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ–∫—É—â–∏–π —Ç–æ–∫–µ–Ω (–¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω –ø–æ—á—Ç–∏ –∏—Å—Ç–µ–∫) –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞.
    
    Headers:
    - Authorization: Bearer {token}
    
    Returns:
    - –ù–æ–≤—ã–π —Ç–æ–∫–µ–Ω –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
    """
    try:
        if not authorization or not authorization.startswith("Bearer "):
            raise HTTPException(status_code=401, detail="Missing or invalid token")

        token = authorization.replace("Bearer ", "")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω (–¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω –ø–æ—á—Ç–∏ –∏—Å—Ç–µ–∫, –Ω–æ –µ—â–µ –≤–∞–ª–∏–¥–µ–Ω)
        payload = verify_jwt(token)
        
        if not payload:
            raise HTTPException(status_code=401, detail="Invalid or expired token")

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –±–∞–∑—ã –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —á—Ç–æ –æ–Ω –µ—â–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        db = get_db()
        user = db.get_user_by_email(payload['email'])
        
        if not user:
            raise HTTPException(status_code=401, detail="User not found")
        
        if not user.get('is_active', True):
            raise HTTPException(status_code=403, detail="User account is disabled")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω
        new_token = create_jwt_token(user['id'], user['email'])

        # –°–æ–∑–¥–∞–µ–º response —Å –Ω–æ–≤—ã–º —Ç–æ–∫–µ–Ω–æ–º
        secure_cookie = os.getenv("ENVIRONMENT", "development").lower() == "production"
        response = JSONResponse(content={
            "token": new_token,
            "user": {
                "id": user['id'],
                "email": user['email'],
                "created_at": user['created_at'].isoformat() if isinstance(user.get('created_at'), datetime) else user.get('created_at')
            },
            "message": "Token refreshed successfully"
        })

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω –≤ cookie
        response.set_cookie(
            key="auth_token",
            value=new_token,
            httponly=True,
            secure=secure_cookie,
            samesite="lax",
            max_age=86400,  # 24 —á–∞—Å–∞
            path="/"
        )

        return response
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Token refresh failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/auth/me", response_model=UserInfo)
async def get_current_user(authorization: str = Header(None)):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (protected endpoint)

    Headers:
    - Authorization: Bearer {token}

    Returns:
    - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
    """
    try:
        if not authorization or not authorization.startswith("Bearer "):
            raise HTTPException(status_code=401, detail="Missing or invalid token")

        token = authorization.replace("Bearer ", "")
        payload = verify_jwt(token)

        if not payload:
            raise HTTPException(status_code=401, detail="Invalid or expired token")

        db = get_db()
        user = db.get_user_by_email(payload['email'])

        if not user:
            raise HTTPException(status_code=401, detail="User not found")

        return UserInfo(**user)
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/auth/logout")
async def logout():
    """
    –í—ã—Ö–æ–¥ –∏–∑ —Å–∏—Å—Ç–µ–º—ã (–æ—á–∏—Å—Ç–∫–∞ cookie)
    """
    response = JSONResponse(content={"message": "Logged out successfully"})
    response.delete_cookie(key="auth_token", path="/")
    return response


@app.get("/api/auth/csrf-token")
async def get_csrf_token(authorization: str = Header(None)):
    """
    –ü–æ–ª—É—á–∏—Ç—å CSRF —Ç–æ–∫–µ–Ω –¥–ª—è –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

    Returns:
    - csrf_token: –¢–æ–∫–µ–Ω –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ X-CSRF-Token
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Authentication required")

    token = authorization.replace("Bearer ", "")
    payload = verify_jwt(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º CSRF —Ç–æ–∫–µ–Ω
    csrf = get_csrf_protection()
    csrf_token = csrf.generate_token(str(payload.get('sub', '')))

    return {
        "csrf_token": csrf_token,
        "header_name": "X-CSRF-Token",
        "expires_in": 3600
    }


# ============================================
# OAuth Endpoints
# ============================================

@app.get("/api/auth/oauth/providers")
async def get_oauth_providers():
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö OAuth –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

    Returns:
    - providers: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –¥–ª—è –≤—Ö–æ–¥–∞
    """
    providers = oauth_manager.list_available_providers()
    return {
        "providers": [
            {
                "name": provider,
                "display_name": provider.capitalize(),
                "icon_url": f"/static/icons/{provider}.svg"
            }
            for provider in providers
        ]
    }


@app.get("/api/auth/oauth/{provider}/login")
async def oauth_login(provider: str):
    """
    –ò–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞—Ç—å OAuth –≤—Ö–æ–¥ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

    Args:
    - provider: –ò–º—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ (google, github, microsoft)

    Returns:
    - authorization_url: URL –¥–ª—è —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    oauth_provider = oauth_manager.get_provider(provider)
    if not oauth_provider:
        raise HTTPException(
            status_code=400,
            detail=f"Provider {provider} is not configured"
        )

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º state –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç CSRF
    state = oauth_provider.generate_state()

    # –ü–æ–ª—É—á–∞–µ–º URL –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    auth_url = oauth_provider.get_authorization_url(state=state)

    return {
        "authorization_url": auth_url,
        "state": state
    }


@app.post("/api/auth/oauth/{provider}/callback")
async def oauth_callback(
    provider: str,
    code: str,
    state: str,
    response: Response
):
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å OAuth callback –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

    Args:
    - provider: –ò–º—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    - code: –ö–æ–¥ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    - state: State –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ CSRF

    Returns:
    - user: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
    - access_token: JWT —Ç–æ–∫–µ–Ω –¥–ª—è API
    """
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º callback
        result = await oauth_manager.handle_callback(provider, code, state)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_info = result["user_info"]
        email = user_info.get("email") or user_info.get("mail")
        name = user_info.get("name") or user_info.get("displayName") or user_info.get("login")

        if not email:
            raise HTTPException(
                status_code=400,
                detail="Email not provided by OAuth provider"
            )

        db = get_db()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        existing_user = db.get_user_by_email(email)

        if existing_user:
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –≤—Ö–æ–¥–µ
            user_id = existing_user["id"]
            db.execute_query(
                """
                UPDATE users
                SET last_login = CURRENT_TIMESTAMP,
                    oauth_provider = ?,
                    oauth_id = ?
                WHERE id = ?
                """,
                (provider, user_info.get("id", ""), user_id)
            )
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_id = db.create_user(
                email=email,
                password_hash="",  # OAuth –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –Ω–µ –∏–º–µ—é—Ç –ø–∞—Ä–æ–ª—è
                username=name or email.split("@")[0],
                oauth_provider=provider,
                oauth_id=user_info.get("id", "")
            )

        # –°–æ–∑–¥–∞–µ–º JWT —Ç–æ–∫–µ–Ω
        token = create_jwt_token({
            "user_id": user_id,
            "email": email,
            "provider": provider
        })

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º cookie
        response.set_cookie(
            key="auth_token",
            value=token,
            httponly=True,
            secure=True,
            samesite="lax",
            max_age=86400  # 24 —á–∞—Å–∞
        )

        return {
            "user": {
                "id": user_id,
                "email": email,
                "name": name,
                "provider": provider
            },
            "access_token": token,
            "token_type": "bearer"
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"OAuth callback error: {e}")
        raise HTTPException(
            status_code=500,
            detail="Failed to process OAuth callback"
        )


# ============================================
# CSRF Protection Dependency
# ============================================

async def verify_csrf_token(
    x_csrf_token: str = Header(None),
    authorization: str = Header(None)
):
    """Dependency –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ CSRF —Ç–æ–∫–µ–Ω–∞"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ CSRF —Ç–æ–∫–µ–Ω–∞
    if not x_csrf_token:
        raise HTTPException(
            status_code=403,
            detail="CSRF token required. Get one from /api/auth/csrf-token"
        )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Authentication required")

    token = authorization.replace("Bearer ", "")
    payload = verify_jwt(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid auth token")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º CSRF —Ç–æ–∫–µ–Ω
    csrf = get_csrf_protection()
    if not csrf.verify_token(x_csrf_token, str(payload.get('sub', ''))):
        raise HTTPException(status_code=403, detail="Invalid CSRF token")

    return payload


# ============================================
# Two-Factor Authentication Endpoints
# ============================================

# Initialize 2FA manager
two_factor = TwoFactorAuth(get_db())

@app.post("/api/auth/2fa/setup")
async def setup_2fa(
    authorization: str = Header(None),
    x_csrf_token: str = Header(None)
):
    """
    –ù–∞—á–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫—É 2FA –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
    - qr_code: Base64 QR –∫–æ–¥ –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    - secret: –°–µ–∫—Ä–µ—Ç–Ω—ã–π –∫–ª—é—á –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞
    - backup_codes: –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–¥—ã
    """
    # Verify authentication
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Authentication required")

    token = authorization.replace("Bearer ", "")
    payload = verify_jwt(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    # Verify CSRF token
    csrf = get_csrf_protection()
    if not csrf.verify_token(x_csrf_token, str(payload.get('sub', ''))):
        raise HTTPException(status_code=403, detail="Invalid CSRF token")

    user_id = payload.get('sub')
    email = payload.get('email', '')

    # Generate 2FA setup
    setup_data = two_factor.generate_secret(user_id, email)

    return {
        "qr_code": f"data:image/png;base64,{setup_data['qr_code']}",
        "secret": setup_data['manual_entry_key'],
        "backup_codes": setup_data['backup_codes']
    }


@app.post("/api/auth/2fa/enable")
async def enable_2fa(
    token: str,
    authorization: str = Header(None),
    x_csrf_token: str = Header(None)
):
    """
    –í–∫–ª—é—á–∏—Ç—å 2FA –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–∫–µ–Ω–∞

    Args:
    - token: 6-–∑–Ω–∞—á–Ω—ã–π TOTP —Ç–æ–∫–µ–Ω

    Returns:
    - enabled: True –µ—Å–ª–∏ 2FA —É—Å–ø–µ—à–Ω–æ –≤–∫–ª—é—á–µ–Ω–∞
    """
    # Verify authentication
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Authentication required")

    jwt_token = authorization.replace("Bearer ", "")
    payload = verify_jwt(jwt_token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    # Verify CSRF token
    csrf = get_csrf_protection()
    if not csrf.verify_token(x_csrf_token, str(payload.get('sub', ''))):
        raise HTTPException(status_code=403, detail="Invalid CSRF token")

    user_id = payload.get('sub')

    # Enable 2FA
    if two_factor.enable_2fa(user_id, token):
        return {"enabled": True, "message": "2FA has been enabled successfully"}
    else:
        raise HTTPException(status_code=400, detail="Invalid token or 2FA setup not found")


@app.post("/api/auth/2fa/disable")
async def disable_2fa(
    password: str,
    authorization: str = Header(None),
    x_csrf_token: str = Header(None)
):
    """
    –û—Ç–∫–ª—é—á–∏—Ç—å 2FA

    Args:
    - password: –ü–∞—Ä–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è

    Returns:
    - disabled: True –µ—Å–ª–∏ 2FA —É—Å–ø–µ—à–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞
    """
    # Verify authentication
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Authentication required")

    token = authorization.replace("Bearer ", "")
    payload = verify_jwt(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    # Verify CSRF token
    csrf = get_csrf_protection()
    if not csrf.verify_token(x_csrf_token, str(payload.get('sub', ''))):
        raise HTTPException(status_code=403, detail="Invalid CSRF token")

    user_id = payload.get('sub')
    email = payload.get('email')

    # Verify password
    db = get_db()
    user = db.get_user_by_email(email)
    if not user or not verify_password(password, user['password_hash']):
        raise HTTPException(status_code=403, detail="Invalid password")

    # Disable 2FA
    if two_factor.disable_2fa(user_id):
        return {"disabled": True, "message": "2FA has been disabled"}
    else:
        raise HTTPException(status_code=400, detail="Failed to disable 2FA")


@app.post("/api/auth/2fa/verify")
async def verify_2fa(
    token: str,
    user_id: int,
    request: Request
):
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å 2FA —Ç–æ–∫–µ–Ω –ø—Ä–∏ –≤—Ö–æ–¥–µ

    Args:
    - token: TOTP —Ç–æ–∫–µ–Ω –∏–ª–∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –∫–æ–¥
    - user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
    - valid: True –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω –≤–∞–ª–∏–¥–µ–Ω
    """
    # Get IP address
    ip_address = request.client.host if request.client else None

    # Check rate limiting
    if not two_factor.check_rate_limit(user_id, ip_address):
        raise HTTPException(
            status_code=429,
            detail="Too many failed attempts. Please try again later."
        )

    # Verify token
    if two_factor.verify_token(user_id, token, ip_address):
        return {"valid": True}
    else:
        raise HTTPException(status_code=403, detail="Invalid 2FA token")


@app.get("/api/auth/2fa/backup-codes")
async def get_backup_codes(
    authorization: str = Header(None)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–¥—ã

    Returns:
    - backup_codes: –°–ø–∏—Å–æ–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–¥–æ–≤
    """
    # Verify authentication
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Authentication required")

    token = authorization.replace("Bearer ", "")
    payload = verify_jwt(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    user_id = payload.get('sub')

    # Get backup codes
    codes = two_factor.get_backup_codes(user_id)

    return {"backup_codes": codes}


@app.post("/api/auth/2fa/regenerate-backup-codes")
async def regenerate_backup_codes(
    authorization: str = Header(None),
    x_csrf_token: str = Header(None)
):
    """
    –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–¥—ã

    Returns:
    - backup_codes: –ù–æ–≤—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–¥—ã
    """
    # Verify authentication
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Authentication required")

    token = authorization.replace("Bearer ", "")
    payload = verify_jwt(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    # Verify CSRF token
    csrf = get_csrf_protection()
    if not csrf.verify_token(x_csrf_token, str(payload.get('sub', ''))):
        raise HTTPException(status_code=403, detail="Invalid CSRF token")

    user_id = payload.get('sub')

    # Regenerate codes
    new_codes = two_factor.regenerate_backup_codes(user_id)

    return {"backup_codes": new_codes}


@app.get("/api/auth/2fa/status")
async def get_2fa_status(
    authorization: str = Header(None)
):
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å 2FA –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
    - enabled: True –µ—Å–ª–∏ 2FA –≤–∫–ª—é—á–µ–Ω–∞
    - recent_attempts: –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ–ø—ã—Ç–∫–∏ –≤—Ö–æ–¥–∞
    """
    # Verify authentication
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Authentication required")

    token = authorization.replace("Bearer ", "")
    payload = verify_jwt(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    user_id = payload.get('sub')

    # Get 2FA status
    enabled = two_factor.is_2fa_enabled(user_id)
    recent_attempts = two_factor.get_recent_attempts(user_id) if enabled else []

    return {
        "enabled": enabled,
        "recent_attempts": recent_attempts
    }


# ============================================
# Schema Validation Helpers
# ============================================

def validate_record_data(data: Dict[str, Any], schema: DatabaseSchema) -> None:
    """
    Validate record data against database schema

    Args:
        data: Record data to validate
        schema: Database schema

    Raises:
        HTTPException: If validation fails
    """
    from datetime import datetime as dt

    # Check required fields
    for column in schema.columns:
        if column.required and column.name not in data:
            raise HTTPException(
                status_code=400,
                detail=f"Required field '{column.name}' is missing"
            )

    # Validate each field
    for field_name, field_value in data.items():
        # Skip system fields
        if field_name in ['id', 'created_at', 'updated_at']:
            continue

        # Find column definition
        column = next((col for col in schema.columns if col.name == field_name), None)
        if not column:
            raise HTTPException(
                status_code=400,
                detail=f"Unknown field '{field_name}' not in schema"
            )

        # Skip validation for None values in optional fields
        if field_value is None and not column.required:
            continue

        # Type validation
        if column.type == 'text':
            if not isinstance(field_value, str):
                raise HTTPException(
                    status_code=400,
                    detail=f"Field '{field_name}' must be a string (got {type(field_value).__name__})"
                )
            # Length validation
            if column.min_length is not None and len(field_value) < column.min_length:
                raise HTTPException(
                    status_code=400,
                    detail=f"Field '{field_name}' must be at least {column.min_length} characters long (got {len(field_value)})"
                )
            if column.max_length is not None and len(field_value) > column.max_length:
                raise HTTPException(
                    status_code=400,
                    detail=f"Field '{field_name}' must be at most {column.max_length} characters long (got {len(field_value)})"
                )

        elif column.type == 'number':
            if not isinstance(field_value, (int, float)):
                # Try to parse string to number
                if isinstance(field_value, str):
                    try:
                        field_value = float(field_value)
                        # Update the data dict with parsed value
                        data[field_name] = field_value
                    except ValueError:
                        raise HTTPException(
                            status_code=400,
                            detail=f"Field '{field_name}' must be a number (got '{field_value}')"
                        )
                else:
                    raise HTTPException(
                        status_code=400,
                        detail=f"Field '{field_name}' must be a number (got {type(field_value).__name__})"
                    )
            # Range validation
            if column.min_value is not None and field_value < column.min_value:
                raise HTTPException(
                    status_code=400,
                    detail=f"Field '{field_name}' must be at least {column.min_value} (got {field_value})"
                )
            if column.max_value is not None and field_value > column.max_value:
                raise HTTPException(
                    status_code=400,
                    detail=f"Field '{field_name}' must be at most {column.max_value} (got {field_value})"
                )

        elif column.type == 'boolean':
            if not isinstance(field_value, bool):
                # Try to parse string to boolean
                if isinstance(field_value, str):
                    if field_value.lower() in ('true', '1', 'yes'):
                        data[field_name] = True
                    elif field_value.lower() in ('false', '0', 'no'):
                        data[field_name] = False
                    else:
                        raise HTTPException(
                            status_code=400,
                            detail=f"Field '{field_name}' must be a boolean (got '{field_value}'). Use true/false"
                        )
                elif isinstance(field_value, (int, float)):
                    data[field_name] = bool(field_value)
                else:
                    raise HTTPException(
                        status_code=400,
                        detail=f"Field '{field_name}' must be a boolean (got {type(field_value).__name__})"
                    )

        elif column.type == 'date':
            if not isinstance(field_value, str):
                raise HTTPException(
                    status_code=400,
                    detail=f"Field '{field_name}' must be a date string in YYYY-MM-DD format (got {type(field_value).__name__})"
                )
            # Validate date format
            try:
                parsed_date = dt.strptime(field_value, '%Y-%m-%d')
                # Validate reasonable date range (1900-2100)
                if parsed_date.year < 1900 or parsed_date.year > 2100:
                    raise HTTPException(
                        status_code=400,
                        detail=f"Field '{field_name}' date must be between 1900 and 2100 (got {parsed_date.year})"
                    )
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail=f"Field '{field_name}' must be in YYYY-MM-DD format (got '{field_value}'). Example: 2025-01-15"
                )

        elif column.type == 'select':
            if not column.options:
                raise HTTPException(
                    status_code=500,
                    detail=f"Field '{field_name}' is select type but has no options defined"
                )
            if field_value not in column.options:
                raise HTTPException(
                    status_code=400,
                    detail=f"Field '{field_name}' must be one of: {', '.join(column.options)} (got '{field_value}')"
                )

# ============================================
# JWT Middleware Helper
# ============================================

def get_current_user_from_token(authorization: str = Header(None)) -> Dict:
    """
    Dependency –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ JWT —Ç–æ–∫–µ–Ω–∞

    Usage:
    ```python
    @app.get("/api/protected")
    async def protected_route(current_user: Dict = Depends(get_current_user_from_token)):
        return {"message": f"Hello {current_user['email']}!"}
    ```
    """
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Missing token")

    token = authorization.replace("Bearer ", "")
    payload = verify_jwt(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Invalid token")

    # Add user_id field for compatibility
    payload['user_id'] = payload['sub']

    return payload


# ============================================
# Rate Limiting Dependency
# ============================================

async def check_rate_limit(
    request: Request,
    authorization: str = Header(None)
):
    """
    Rate limiting dependency - –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–∏–º–∏—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤

    Usage:
    ```python
    @app.get("/api/endpoint", dependencies=[Depends(check_rate_limit)])
    async def endpoint():
        return {"data": "..."}
    ```
    """
    limiter = get_rate_limiter()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏ tier
    if authorization and authorization.startswith("Bearer "):
        token = authorization.replace("Bearer ", "")
        payload = verify_jwt(token)
        if payload:
            identifier = f"user_{payload['sub']}"
            tier = 'authenticated'
        else:
            # Invalid token - use IP
            identifier = request.client.host if request.client else "unknown"
            tier = 'anonymous'
    else:
        # No token - use IP address
        identifier = request.client.host if request.client else "unknown"
        tier = 'anonymous'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º rate limit
    if not limiter.check_rate_limit(identifier, tier):
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        remaining = limiter.get_remaining(identifier, tier)
        reset_time = limiter.get_reset_time(identifier, tier)

        raise HTTPException(
            status_code=429,
            detail="Too many requests. Please slow down.",
            headers={
                "X-RateLimit-Limit": "100" if tier == 'authenticated' else "10",
                "X-RateLimit-Remaining": str(remaining),
                "X-RateLimit-Reset": str(reset_time),
                "Retry-After": str(reset_time)
            }
        )

    # Rate limit OK - –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    remaining = limiter.get_remaining(identifier, tier)
    # Headers –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ middleware
    request.state.rate_limit_remaining = remaining


# Example of protected endpoint
@app.get("/api/protected-example")
async def protected_route_example(current_user: Dict = Depends(get_current_user_from_token)):
    """
    –ü—Ä–∏–º–µ—Ä –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞

    –¢—Ä–µ–±—É–µ—Ç –≤–∞–ª–∏–¥–Ω—ã–π JWT —Ç–æ–∫–µ–Ω –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ Authorization
    """
    return {
        "message": f"Hello {current_user['email']}!",
        "user_id": current_user['id'],
        "member_since": current_user['created_at']
    }

# ============================================
# Session Management Endpoints
# ============================================

@app.post("/api/sessions/create")
async def create_session(current_user = Depends(get_current_user)):
    """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é —á–∞—Ç-—Å–µ—Å—Å–∏—é –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        db = get_db()
        session_id = db.create_session(user_id=current_user['id'])
        return {"session_id": session_id, "success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/sessions/{session_id}/messages")
async def get_session_messages(session_id: str, current_user = Depends(get_current_user)):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–∞)"""
    try:
        db = get_db()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ —Å–µ—Å—Å–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        if not db.session_belongs_to_user(session_id, current_user['id']):
            raise HTTPException(status_code=403, detail="Access denied to this session")
        messages = db.get_session_messages(session_id)
        return {"session_id": session_id, "messages": messages, "count": len(messages)}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/sessions")
async def get_all_sessions(current_user = Depends(get_current_user)):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–µ—Å—Å–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        db = get_db()
        sessions = db.get_user_sessions(current_user['id'])
        return {"sessions": sessions, "count": len(sessions)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/sessions/{session_id}")
async def delete_session(session_id: str, current_user = Depends(get_current_user)):
    """–£–¥–∞–ª–∏—Ç—å —Å–µ—Å—Å–∏—é (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–∞)"""
    try:
        db = get_db()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ —Å–µ—Å—Å–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        if not db.session_belongs_to_user(session_id, current_user['id']):
            raise HTTPException(status_code=403, detail="Access denied to this session")
        db.delete_session(session_id)
        return {"success": True, "message": f"Session {session_id} deleted"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# Projects Management Endpoints
# ============================================

@app.post("/api/projects", response_model=ProjectDetail)
async def create_project(
    request: ProjectCreate,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç

    –¢—Ä–µ–±—É–µ—Ç—Å—è JWT –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è.

    Args:
        request: –î–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞ (name, description)
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ (user_id)

    Returns:
        ProjectDetail: –°–æ–∑–¥–∞–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç
    """
    try:
        db = get_db()
        logger.info(f"Creating project '{request.name}' for user {token_data['user_id']}")

        project_id = db.create_project(
            user_id=token_data['user_id'],
            name=request.name,
            description=request.description
        )

        project = db.get_project(project_id, token_data['user_id'])
        if not project:
            raise HTTPException(status_code=500, detail="Failed to create project")

        # Add database count
        project['database_count'] = 0  # New project has no databases yet

        logger.info(f"Project created successfully: ID={project_id}")
        return ProjectDetail(**project)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating project: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/projects", response_model=List[ProjectDetail])
async def list_projects(token_data: dict = Depends(get_current_user_from_token)):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    –¢—Ä–µ–±—É–µ—Ç—Å—è JWT –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è.

    Args:
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ (user_id)

    Returns:
        List[ProjectDetail]: –°–ø–∏—Å–æ–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤
    """
    try:
        db = get_db()
        logger.info(f"Fetching projects for user {token_data['user_id']}")

        projects = db.get_projects(token_data['user_id'])

        # Add database count for each project
        result = []
        for project in projects:
            databases = db.get_databases(project['id'])
            project['database_count'] = len(databases)
            result.append(ProjectDetail(**project))

        logger.info(f"Found {len(result)} projects")
        return result
    except Exception as e:
        logger.error(f"Error fetching projects: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/projects/{project_id}", response_model=ProjectDetail)
async def get_project_detail(
    project_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

    –¢—Ä–µ–±—É–µ—Ç—Å—è JWT –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è.

    Args:
        project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ (user_id)

    Returns:
        ProjectDetail: –î–µ—Ç–∞–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
    """
    try:
        db = get_db()
        logger.info(f"Fetching project {project_id} for user {token_data['user_id']}")

        project = db.get_project(project_id, token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")

        # Add database count
        databases = db.get_databases(project['id'])
        project['database_count'] = len(databases)

        return ProjectDetail(**project)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching project: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/projects/{project_id}", response_model=ProjectDetail)
async def update_project(
    project_id: int,
    request: ProjectUpdate,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–µ–∫—Ç

    –¢—Ä–µ–±—É–µ—Ç—Å—è JWT –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è.

    Args:
        project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
        request: –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (name, description)
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ (user_id)

    Returns:
        ProjectDetail: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç
    """
    try:
        db = get_db()
        logger.info(f"Updating project {project_id} for user {token_data['user_id']}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
        existing = db.get_project(project_id, token_data['user_id'])
        if not existing:
            raise HTTPException(status_code=404, detail="Project not found")

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—è
        name = request.name if request.name is not None else existing['name']
        description = request.description if request.description is not None else existing.get('description')

        success = db.update_project(
            project_id=project_id,
            user_id=token_data['user_id'],
            name=name,
            description=description
        )

        if not success:
            raise HTTPException(status_code=404, detail="Project not found or update failed")

        # –ü–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç
        project = db.get_project(project_id, token_data['user_id'])
        databases = db.get_databases(project['id'])
        project['database_count'] = len(databases)

        logger.info(f"Project {project_id} updated successfully")
        return ProjectDetail(**project)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating project: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/projects/{project_id}")
async def delete_project(
    project_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –£–¥–∞–ª–∏—Ç—å –ø—Ä–æ–µ–∫—Ç

    –¢—Ä–µ–±—É–µ—Ç—Å—è JWT –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è.
    –¢–∞–∫–∂–µ —É–¥–∞–ª—è–µ—Ç –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–ø–∏—Å–∏.

    Args:
        project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ (user_id)

    Returns:
        dict: –°—Ç–∞—Ç—É—Å –æ–ø–µ—Ä–∞—Ü–∏–∏
    """
    try:
        db = get_db()
        logger.info(f"Deleting project {project_id} for user {token_data['user_id']}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
        existing = db.get_project(project_id, token_data['user_id'])
        if not existing:
            raise HTTPException(status_code=404, detail="Project not found")

        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞ (cascade)
        databases = db.get_databases(project_id)
        for database in databases:
            db.delete_database(database['id'])

        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–µ–∫—Ç
        success = db.delete_project(project_id, token_data['user_id'])
        if not success:
            raise HTTPException(status_code=404, detail="Project not found")

        logger.info(f"Project {project_id} deleted successfully")
        return {"success": True, "message": "Project deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting project: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# Databases Management Endpoints
# ============================================

@app.post("/api/databases", response_model=DatabaseResponse)
async def create_database(
    request: DatabaseCreate,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤ –ø—Ä–æ–µ–∫—Ç–µ

    Args:
        request: –î–∞–Ω–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (project_id, name, schema)
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        DatabaseResponse: –°–æ–∑–¥–∞–Ω–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        db = get_db()

        # Verify project belongs to user
        project = db.get_project(request.project_id, token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")

        # Convert schema to DatabaseSchema if it's a list
        if isinstance(request.schema, list):
            # Test sends schema as list of dicts like [{'name': 'name', 'type': 'text'}]
            columns = [ColumnDefinition(**col) if isinstance(col, dict) else col for col in request.schema]
            schema_obj = DatabaseSchema(columns=columns)
        else:
            schema_obj = request.schema

        # Validate schema - check for duplicate column names
        column_names = [col.name for col in schema_obj.columns]
        if len(column_names) != len(set(column_names)):
            raise HTTPException(status_code=400, detail="Duplicate column names in schema")

        # Check select type columns have options
        for col in schema_obj.columns:
            if col.type == 'select' and not col.options:
                raise HTTPException(
                    status_code=400,
                    detail=f"Column '{col.name}' is select type but has no options"
                )

        logger.info(f"Creating database '{request.name}' in project {request.project_id}")

        # Store schema as JSON
        schema_json = json.dumps(schema_obj.model_dump())
        database_id = db.create_database(request.project_id, request.name, schema_json)

        # Retrieve created database
        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=500, detail="Failed to create database")

        # Parse schema and add record count
        schema_data = json.loads(database['schema_json'])
        database['schema'] = DatabaseSchema(**schema_data)
        database['record_count'] = 0

        logger.info(f"Database created successfully: ID={database_id}")
        return DatabaseResponse(**database)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating database: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/databases", response_model=List[DatabaseResponse])
async def list_databases(
    project_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞

    Args:
        project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        List[DatabaseResponse]: –°–ø–∏—Å–æ–∫ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        db = get_db()

        # Verify project belongs to user
        project = db.get_project(project_id, token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")

        logger.info(f"Fetching databases for project {project_id}")
        databases = db.get_databases(project_id)

        result = []
        for database in databases:
            # Parse schema
            schema_data = json.loads(database['schema_json'])
            database['schema'] = DatabaseSchema(**schema_data)

            # Add record count
            records = db.get_records(database['id'])
            database['record_count'] = len(records)

            result.append(DatabaseResponse(**database))

        logger.info(f"Found {len(result)} databases")
        return result
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching databases: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/databases/{database_id}", response_model=DatabaseResponse)
async def get_database_detail(
    database_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        DatabaseResponse: –î–µ—Ç–∞–ª–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        db = get_db()

        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        # Verify project belongs to user
        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        # Parse schema
        schema_data = json.loads(database['schema_json'])
        database['schema'] = DatabaseSchema(**schema_data)

        # Add record count
        records = db.get_records(database['id'])
        database['record_count'] = len(records)

        return DatabaseResponse(**database)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching database: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/databases/{database_id}")
async def delete_database(
    database_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –£–¥–∞–ª–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        dict: –°—Ç–∞—Ç—É—Å –æ–ø–µ—Ä–∞—Ü–∏–∏
    """
    try:
        db = get_db()

        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        # Verify project belongs to user
        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        logger.info(f"Deleting database {database_id}")
        success = db.delete_database(database_id)

        if not success:
            raise HTTPException(status_code=404, detail="Database not found")

        logger.info(f"Database {database_id} deleted successfully")
        return {"success": True, "message": "Database deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting database: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# Database Records Management Endpoints
# ============================================

@app.post("/api/records", response_model=RecordResponse)
async def create_record_simple(
    request: RecordCreate,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π endpoint)

    Args:
        request: –î–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å database_id
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        RecordResponse: –°–æ–∑–¥–∞–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å
    """
    if not request.database_id:
        raise HTTPException(status_code=400, detail="database_id is required")

    # Redirect to the main endpoint
    return await create_record(request.database_id, request, token_data)

@app.post("/api/databases/{database_id}/records", response_model=RecordResponse)
async def create_record(
    database_id: int,
    request: RecordCreate,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        request: –î–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        RecordResponse: –°–æ–∑–¥–∞–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å
    """
    try:
        db = get_db()

        # Get database and verify access
        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        # Parse schema
        schema_data = json.loads(database['schema_json'])
        schema = DatabaseSchema(**schema_data)

        # Validate record data against schema
        validate_record_data(request.data, schema)

        logger.info(f"Creating record in database {database_id}")

        # Store record as JSON
        data_json = json.dumps(request.data)
        record_id = db.create_record(database_id, data_json)

        # Retrieve created record
        record = db.get_record(record_id)
        if not record:
            raise HTTPException(status_code=500, detail="Failed to create record")

        # Parse data
        record['data'] = json.loads(record['data_json'])

        logger.info(f"Record created successfully: ID={record_id}")
        return RecordResponse(**record)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating record: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/databases/{database_id}/records", response_model=List[RecordResponse])
async def list_records(
    database_id: int,
    limit: int = 100,
    offset: int = 0,
    search: Optional[str] = None,
    sort_by: Optional[str] = None,
    sort_order: Optional[str] = 'asc',
    filter_field: Optional[str] = None,
    filter_value: Optional[str] = None,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–∏—Å–∫–æ–º –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π (max 100)
        offset: –°–º–µ—â–µ–Ω–∏–µ –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        search: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–∏—â–µ—Ç –ø–æ –≤—Å–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø–æ–ª—è–º)
        sort_by: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        sort_order: –ü–æ—Ä—è–¥–æ–∫ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ (asc/desc)
        filter_field: –ü–æ–ª–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        filter_value: –ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        List[RecordResponse]: –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π
    """
    try:
        db = get_db()

        # Get database and verify access
        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        # Parse schema for validation
        schema_data = json.loads(database['schema_json'])
        schema = DatabaseSchema(**schema_data)

        # Enforce limit cap
        if limit > 100:
            limit = 100

        logger.info(f"Fetching records from database {database_id} with search='{search}', filter={filter_field}={filter_value}")

        # Get all records (we'll filter in memory for now)
        # TODO: Move filtering to database layer for better performance
        all_records = db.get_records(database_id, limit=1000, offset=0)

        result = []
        for record in all_records:
            # Parse data
            record['data'] = json.loads(record['data_json'])

            # Apply search filter
            if search:
                search_lower = search.lower()
                found = False
                for col in schema.columns:
                    if col.type == 'text' and col.name in record['data']:
                        field_value = str(record['data'][col.name])
                        if search_lower in field_value.lower():
                            found = True
                            break
                if not found:
                    continue

            # Apply field filter
            if filter_field and filter_value:
                if filter_field not in record['data']:
                    continue
                record_value = str(record['data'][filter_field])
                # For exact match on select/boolean, partial match on text
                col = next((c for c in schema.columns if c.name == filter_field), None)
                if col:
                    if col.type in ['select', 'boolean', 'date']:
                        if record_value != filter_value:
                            continue
                    elif col.type == 'number':
                        try:
                            if float(record_value) != float(filter_value):
                                continue
                        except ValueError:
                            continue
                    else:  # text
                        if filter_value.lower() not in record_value.lower():
                            continue

            result.append(RecordResponse(**record))

        # Apply sorting
        if sort_by:
            col = next((c for c in schema.columns if c.name == sort_by), None)
            if col:
                def get_sort_key(r):
                    value = r.data.get(sort_by)
                    if value is None:
                        return '' if col.type == 'text' else 0
                    if col.type == 'number':
                        return float(value) if isinstance(value, (int, float)) else 0
                    return str(value)

                result.sort(key=get_sort_key, reverse=(sort_order == 'desc'))

        # Apply pagination
        result = result[offset:offset + limit]

        logger.info(f"Found {len(result)} records after filtering")
        return result
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching records: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/databases/{database_id}/records/{record_id}", response_model=RecordResponse)
async def get_record_detail(
    database_id: int,
    record_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–ø–∏—Å—å

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        record_id: ID –∑–∞–ø–∏—Å–∏
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        RecordResponse: –î–µ—Ç–∞–ª–∏ –∑–∞–ø–∏—Å–∏
    """
    try:
        db = get_db()

        # Get database and verify access
        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        # Get record
        record = db.get_record(record_id)
        if not record:
            raise HTTPException(status_code=404, detail="Record not found")

        # Verify record belongs to the specified database
        if record['database_id'] != database_id:
            raise HTTPException(status_code=404, detail="Record not found")

        # Parse data
        record['data'] = json.loads(record['data_json'])

        return RecordResponse(**record)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching record: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/databases/{database_id}/records/{record_id}", response_model=RecordResponse)
async def update_record(
    database_id: int,
    record_id: int,
    request: RecordUpdate,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –û–±–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        record_id: ID –∑–∞–ø–∏—Å–∏
        request: –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        RecordResponse: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å
    """
    try:
        db = get_db()

        # Get database and verify access
        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        # Get record
        record = db.get_record(record_id)
        if not record:
            raise HTTPException(status_code=404, detail="Record not found")

        # Verify record belongs to the specified database
        if record['database_id'] != database_id:
            raise HTTPException(status_code=404, detail="Record not found")

        # Parse schema
        schema_data = json.loads(database['schema_json'])
        schema = DatabaseSchema(**schema_data)

        # Validate new data against schema
        validate_record_data(request.data, schema)

        logger.info(f"Updating record {record_id}")

        # Update record
        data_json = json.dumps(request.data)
        success = db.update_record(record_id, data_json)

        if not success:
            raise HTTPException(status_code=404, detail="Record not found")

        # Get updated record
        record = db.get_record(record_id)
        record['data'] = json.loads(record['data_json'])

        logger.info(f"Record {record_id} updated successfully")
        return RecordResponse(**record)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating record: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/databases/{database_id}/records/{record_id}")
async def delete_record(
    database_id: int,
    record_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –£–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å—å

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        record_id: ID –∑–∞–ø–∏—Å–∏
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        dict: –°—Ç–∞—Ç—É—Å –æ–ø–µ—Ä–∞—Ü–∏–∏
    """
    try:
        db = get_db()

        # Get database and verify access
        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        # Get record
        record = db.get_record(record_id)
        if not record:
            raise HTTPException(status_code=404, detail="Record not found")

        # Verify record belongs to the specified database
        if record['database_id'] != database_id:
            raise HTTPException(status_code=404, detail="Record not found")

        logger.info(f"Deleting record {record_id}")
        success = db.delete_record(record_id)

        if not success:
            raise HTTPException(status_code=404, detail="Record not found")

        logger.info(f"Record {record_id} deleted successfully")
        return {"success": True, "message": "Record deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting record: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# CSV Import/Export Endpoints
# ============================================

@app.get("/api/databases/{database_id}/export/csv")
async def export_records_csv(
    database_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø–∏—Å–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤ CSV

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        CSV file with records
    """
    try:
        db = get_db()

        # Get database and verify access
        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        # Parse schema
        schema_data = json.loads(database['schema_json'])
        schema = DatabaseSchema(**schema_data)

        # Get all records
        records = db.get_records(database_id, limit=10000, offset=0)

        # Create CSV in memory
        output = io.StringIO()

        # Column names from schema
        fieldnames = [col.name for col in schema.columns]
        writer = csv.DictWriter(output, fieldnames=fieldnames, extrasaction='ignore')

        # Write header
        writer.writeheader()

        # Write records
        for record in records:
            data = json.loads(record['data_json'])
            # Only include fields that are in schema
            row = {field: data.get(field, '') for field in fieldnames}
            writer.writerow(row)

        # Get CSV content
        csv_content = output.getvalue()
        output.close()

        logger.info(f"Exported {len(records)} records from database {database_id}")

        # Return as downloadable file
        return Response(
            content=csv_content,
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=database_{database_id}_{database['name']}.csv"
            }
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error exporting CSV: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class CSVImportRequest(BaseModel):
    """Request model for CSV import"""
    csv_content: str = Field(..., description="CSV content as string")
    skip_header: bool = Field(default=True, description="Skip first row as header")
    overwrite: bool = Field(default=False, description="Overwrite existing records")


@app.post("/api/databases/{database_id}/import/csv")
async def import_records_csv(
    database_id: int,
    request: CSVImportRequest,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø–∏—Å–∏ –∏–∑ CSV –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

    Args:
        database_id: ID –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        request: CSV content and options
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        dict: Import statistics
    """
    try:
        db = get_db()

        # Get database and verify access
        database = db.get_database(database_id)
        if not database:
            raise HTTPException(status_code=404, detail="Database not found")

        project = db.get_project(database['project_id'], token_data['user_id'])
        if not project:
            raise HTTPException(status_code=404, detail="Database not found")

        # Parse schema
        schema_data = json.loads(database['schema_json'])
        schema = DatabaseSchema(**schema_data)

        # Parse CSV
        csv_file = io.StringIO(request.csv_content)
        reader = csv.DictReader(csv_file) if request.skip_header else csv.reader(csv_file)

        imported_count = 0
        error_count = 0
        errors = []

        # Clear existing records if overwrite
        if request.overwrite:
            existing_records = db.get_records(database_id, limit=10000, offset=0)
            for record in existing_records:
                db.delete_record(record['id'])
            logger.info(f"Deleted {len(existing_records)} existing records")

        # Process each row
        for idx, row in enumerate(reader, start=1):
            try:
                if isinstance(row, list):
                    # If not using DictReader, map to column names
                    data = {schema.columns[i].name: row[i] for i in range(min(len(row), len(schema.columns)))}
                else:
                    # DictReader returns dict
                    data = dict(row)

                # Validate and create record
                validate_record_data(data, schema)
                data_json = json.dumps(data)
                db.create_record(database_id, data_json)
                imported_count += 1

            except Exception as e:
                error_count += 1
                errors.append(f"Row {idx}: {str(e)}")
                if error_count > 10:  # Limit error collection
                    errors.append("... (more errors truncated)")
                    break

        logger.info(f"CSV import complete: {imported_count} imported, {error_count} errors")

        return {
            "success": True,
            "imported": imported_count,
            "errors": error_count,
            "error_details": errors[:10]  # Return first 10 errors
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error importing CSV: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# Workflows Management
# ============================================

@app.post("/api/workflows", response_model=WorkflowResponse)
async def create_workflow(
    workflow: WorkflowCreate,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –°–æ–∑–¥–∞—Ç—å workflow

    Args:
        workflow: –î–∞–Ω–Ω—ã–µ workflow
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        WorkflowResponse: –°–æ–∑–¥–∞–Ω–Ω—ã–π workflow
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        # Convert trigger and actions to JSON
        trigger_json = json.dumps(workflow.trigger.dict())
        actions_json = json.dumps([action.dict() for action in workflow.actions])

        logger.info(f"Creating workflow: {workflow.name} for user {user_id}")

        with sqlite3.connect(db.db_path) as conn:
            cursor = conn.execute("""
                INSERT INTO workflows (user_id, name, trigger_type, trigger_config, actions_json, enabled)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                user_id,
                workflow.name,
                workflow.trigger.type,
                trigger_json,
                actions_json,
                1 if workflow.enabled else 0
            ))

            workflow_id = cursor.lastrowid
            conn.commit()

        # Fetch the created workflow
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM workflows WHERE id = ?", (workflow_id,))
            row = cursor.fetchone()

        if not row:
            raise HTTPException(status_code=500, detail="Failed to create workflow")

        # Parse JSON fields
        trigger_data = json.loads(row['trigger_config']) if row['trigger_config'] else {"type": row['trigger_type'], "config": {}}
        actions_data = json.loads(row['actions_json'])

        logger.info(f"Workflow {workflow_id} created successfully")

        return WorkflowResponse(
            id=row['id'],
            user_id=row['user_id'],
            name=row['name'],
            trigger=WorkflowTrigger(**trigger_data),
            actions=[WorkflowAction(**action) for action in actions_data],
            enabled=bool(row['enabled']),
            created_at=row['created_at']
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating workflow: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/workflows", response_model=List[WorkflowResponse])
async def list_workflows(
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ workflows –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Args:
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        List[WorkflowResponse]: –°–ø–∏—Å–æ–∫ workflows
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflows
                WHERE user_id = ?
                ORDER BY created_at DESC
            """, (user_id,))

            rows = cursor.fetchall()

        workflows = []
        for row in rows:
            trigger_data = json.loads(row['trigger_config']) if row['trigger_config'] else {"type": row['trigger_type'], "config": {}}
            actions_data = json.loads(row['actions_json'])

            workflows.append(WorkflowResponse(
                id=row['id'],
                user_id=row['user_id'],
                name=row['name'],
                trigger=WorkflowTrigger(**trigger_data),
                actions=[WorkflowAction(**action) for action in actions_data],
                enabled=bool(row['enabled']),
                created_at=row['created_at']
            ))

        logger.info(f"Found {len(workflows)} workflows for user {user_id}")
        return workflows
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing workflows: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/workflows/{workflow_id}", response_model=WorkflowResponse)
async def get_workflow(
    workflow_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å workflow –ø–æ ID

    Args:
        workflow_id: ID workflow
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        WorkflowResponse: –î–∞–Ω–Ω—ã–µ workflow
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflows
                WHERE id = ? AND user_id = ?
            """, (workflow_id, user_id))

            row = cursor.fetchone()

        if not row:
            raise HTTPException(status_code=404, detail="Workflow not found")

        trigger_data = json.loads(row['trigger_config']) if row['trigger_config'] else {"type": row['trigger_type'], "config": {}}
        actions_data = json.loads(row['actions_json'])

        return WorkflowResponse(
            id=row['id'],
            user_id=row['user_id'],
            name=row['name'],
            trigger=WorkflowTrigger(**trigger_data),
            actions=[WorkflowAction(**action) for action in actions_data],
            enabled=bool(row['enabled']),
            created_at=row['created_at']
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting workflow: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/workflows/{workflow_id}", response_model=WorkflowResponse)
async def update_workflow(
    workflow_id: int,
    workflow: WorkflowUpdate,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –û–±–Ω–æ–≤–∏—Ç—å workflow

    Args:
        workflow_id: ID workflow
        workflow: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        WorkflowResponse: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π workflow
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        # Verify workflow exists and belongs to user
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflows
                WHERE id = ? AND user_id = ?
            """, (workflow_id, user_id))

            existing = cursor.fetchone()

        if not existing:
            raise HTTPException(status_code=404, detail="Workflow not found")

        # Build update query
        updates = []
        params = []

        if workflow.name is not None:
            updates.append("name = ?")
            params.append(workflow.name)

        if workflow.trigger is not None:
            updates.append("trigger_type = ?")
            updates.append("trigger_config = ?")
            params.append(workflow.trigger.type)
            params.append(json.dumps(workflow.trigger.dict()))

        if workflow.actions is not None:
            updates.append("actions_json = ?")
            params.append(json.dumps([action.dict() for action in workflow.actions]))

        if workflow.enabled is not None:
            updates.append("enabled = ?")
            params.append(1 if workflow.enabled else 0)

        if not updates:
            # No updates, just return existing
            raise HTTPException(status_code=400, detail="No fields to update")

        params.append(workflow_id)
        params.append(user_id)

        logger.info(f"Updating workflow {workflow_id}")

        with sqlite3.connect(db.db_path) as conn:
            conn.execute(f"""
                UPDATE workflows
                SET {', '.join(updates)}
                WHERE id = ? AND user_id = ?
            """, tuple(params))
            conn.commit()

        # Fetch updated workflow
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflows
                WHERE id = ? AND user_id = ?
            """, (workflow_id, user_id))

            row = cursor.fetchone()

        trigger_data = json.loads(row['trigger_config']) if row['trigger_config'] else {"type": row['trigger_type'], "config": {}}
        actions_data = json.loads(row['actions_json'])

        logger.info(f"Workflow {workflow_id} updated successfully")

        return WorkflowResponse(
            id=row['id'],
            user_id=row['user_id'],
            name=row['name'],
            trigger=WorkflowTrigger(**trigger_data),
            actions=[WorkflowAction(**action) for action in actions_data],
            enabled=bool(row['enabled']),
            created_at=row['created_at']
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating workflow: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/workflows/{workflow_id}")
async def delete_workflow(
    workflow_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –£–¥–∞–ª–∏—Ç—å workflow

    Args:
        workflow_id: ID workflow
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        dict: –°—Ç–∞—Ç—É—Å –æ–ø–µ—Ä–∞—Ü–∏–∏
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        # Verify workflow exists and belongs to user
        with sqlite3.connect(db.db_path) as conn:
            cursor = conn.execute("""
                SELECT id FROM workflows
                WHERE id = ? AND user_id = ?
            """, (workflow_id, user_id))

            if not cursor.fetchone():
                raise HTTPException(status_code=404, detail="Workflow not found")

        logger.info(f"Deleting workflow {workflow_id}")

        with sqlite3.connect(db.db_path) as conn:
            # Delete workflow executions first
            conn.execute("DELETE FROM workflow_executions WHERE workflow_id = ?", (workflow_id,))
            # Delete workflow
            conn.execute("DELETE FROM workflows WHERE id = ? AND user_id = ?", (workflow_id, user_id))
            conn.commit()

        logger.info(f"Workflow {workflow_id} deleted successfully")
        return {"success": True, "message": "Workflow deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting workflow: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/workflows/{workflow_id}/execute", response_model=ExecutionResponse)
async def execute_workflow(
    workflow_id: int,
    context: Dict[str, Any] = {},
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –í—ã–ø–æ–ª–Ω–∏—Ç—å workflow –≤—Ä—É—á–Ω—É—é

    Args:
        workflow_id: ID workflow
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        ExecutionResponse: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        # Verify workflow exists and belongs to user
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflows
                WHERE id = ? AND user_id = ?
            """, (workflow_id, user_id))

            workflow_row = cursor.fetchone()

        if not workflow_row:
            raise HTTPException(status_code=404, detail="Workflow not found")

        if not workflow_row['enabled']:
            raise HTTPException(status_code=400, detail="Workflow is disabled")

        logger.info(f"Executing workflow {workflow_id}")

        # Execute workflow using WorkflowEngine
        from agents.workflow_engine import WorkflowEngine

        engine = WorkflowEngine()
        result = engine.execute(workflow_id, context)

        # Get the execution record that was created by the engine
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflow_executions
                WHERE id = ?
            """, (result['execution_id'],))

            execution_row = cursor.fetchone()

        if not execution_row:
            raise HTTPException(status_code=500, detail="Execution not found")

        result_data = json.loads(execution_row['result_json']) if execution_row['result_json'] else None

        logger.info(f"Workflow {workflow_id} executed successfully")

        return ExecutionResponse(
            id=execution_row['id'],
            workflow_id=execution_row['workflow_id'],
            status=execution_row['status'],
            result={"success": result['success'], "results": result.get('results', [])},
            error=execution_row['error'],
            executed_at=execution_row['executed_at']
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error executing workflow: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/workflows/{workflow_id}/executions", response_model=List[ExecutionResponse])
async def list_executions(
    workflow_id: int,
    limit: int = 50,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π workflow

    Args:
        workflow_id: ID workflow
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        token_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞

    Returns:
        List[ExecutionResponse]: –°–ø–∏—Å–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        # Verify workflow exists and belongs to user
        with sqlite3.connect(db.db_path) as conn:
            cursor = conn.execute("""
                SELECT id FROM workflows
                WHERE id = ? AND user_id = ?
            """, (workflow_id, user_id))

            if not cursor.fetchone():
                raise HTTPException(status_code=404, detail="Workflow not found")

        # Fetch executions
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflow_executions
                WHERE workflow_id = ?
                ORDER BY executed_at DESC
                LIMIT ?
            """, (workflow_id, min(limit, 100)))

            rows = cursor.fetchall()

        executions = []
        for row in rows:
            result_json = row['result_json']
            result_data = None

            if result_json:
                parsed = json.loads(result_json)
                # Wrap list results in a dict for Pydantic validation
                if isinstance(parsed, list):
                    result_data = {"results": parsed}
                else:
                    result_data = parsed

            executions.append(ExecutionResponse(
                id=row['id'],
                workflow_id=row['workflow_id'],
                status=row['status'],
                result=result_data,
                error=row['error'],
                executed_at=row['executed_at']
            ))

        logger.info(f"Found {len(executions)} executions for workflow {workflow_id}")
        return executions
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing executions: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# Webhook Trigger Endpoints
# ============================================

@app.post("/api/webhooks/{workflow_id}/{token}")
async def webhook_trigger(
    workflow_id: int,
    token: str,
    request: Request
):
    """
    Public webhook endpoint for triggering workflows

    Args:
        workflow_id: ID of workflow to trigger
        token: Secret token for authentication (generated per workflow)
        request: FastAPI request object (to access body/headers)

    Returns:
        Execution result

    Example webhook URLs:
        POST https://yourapi.com/api/webhooks/123/abc123def456
        Body: {"event": "payment_completed", "amount": 100}
    """
    try:
        db = get_db()

        # Verify workflow exists and is enabled
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflows
                WHERE id = ? AND trigger_type = 'webhook' AND enabled = 1
            """, (workflow_id,))

            workflow_row = cursor.fetchone()

        if not workflow_row:
            raise HTTPException(status_code=404, detail="Webhook workflow not found or disabled")

        # Verify webhook token
        trigger_config = json.loads(workflow_row['trigger_config']) if workflow_row['trigger_config'] else {}
        expected_token = trigger_config.get('webhook_token', '')

        if not expected_token or expected_token != token:
            logger.warning(f"Invalid webhook token for workflow {workflow_id}")
            raise HTTPException(status_code=401, detail="Invalid webhook token")

        # Parse webhook payload
        try:
            body = await request.json()
        except:
            body = {}

        # Get headers
        headers = dict(request.headers)

        # Build context with webhook data
        context = {
            'trigger': 'webhook',
            'webhook': {
                'workflow_id': workflow_id,
                'body': body,
                'headers': headers,
                'method': request.method,
                'url': str(request.url)
            },
            'triggered_at': datetime.now().isoformat()
        }

        logger.info(f"Webhook received for workflow {workflow_id}")

        # Execute workflow
        from agents.workflow_engine import WorkflowEngine
        engine = WorkflowEngine()
        result = engine.execute(workflow_id, context)

        return {
            "success": result['success'],
            "workflow_id": workflow_id,
            "execution_id": result.get('execution_id'),
            "message": "Webhook processed successfully"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error processing webhook: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/workflows/{workflow_id}/webhook-url")
async def get_webhook_url(
    workflow_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    Get webhook URL for a workflow

    Args:
        workflow_id: ID of workflow
        token_data: User authentication

    Returns:
        Webhook URL and configuration
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        # Verify workflow exists and belongs to user
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflows
                WHERE id = ? AND user_id = ?
            """, (workflow_id, user_id))

            workflow_row = cursor.fetchone()

        if not workflow_row:
            raise HTTPException(status_code=404, detail="Workflow not found")

        # Get or generate webhook token
        trigger_config = json.loads(workflow_row['trigger_config']) if workflow_row['trigger_config'] else {}

        if 'webhook_token' not in trigger_config:
            # Generate new token
            import secrets
            webhook_token = secrets.token_urlsafe(32)

            trigger_config['webhook_token'] = webhook_token

            # Update workflow
            with sqlite3.connect(db.db_path) as conn:
                conn.execute("""
                    UPDATE workflows
                    SET trigger_config = ?
                    WHERE id = ?
                """, (json.dumps(trigger_config), workflow_id))
                conn.commit()
        else:
            webhook_token = trigger_config['webhook_token']

        # Build webhook URL (use environment variable or default)
        base_url = os.getenv('API_BASE_URL', 'http://localhost:8000')
        webhook_url = f"{base_url}/api/webhooks/{workflow_id}/{webhook_token}"

        return {
            "workflow_id": workflow_id,
            "webhook_url": webhook_url,
            "webhook_token": webhook_token,
            "instructions": "POST to this URL with JSON body to trigger the workflow"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting webhook URL: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/workflows/{workflow_id}/register-schedule")
async def register_schedule(
    workflow_id: int,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    Register a schedule workflow with the scheduler

    Args:
        workflow_id: ID of workflow to register
        token_data: User authentication

    Returns:
        Registration status
    """
    try:
        db = get_db()
        user_id = token_data['user_id']

        # Verify workflow exists, belongs to user, and is schedule type
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM workflows
                WHERE id = ? AND user_id = ? AND trigger_type = 'schedule'
            """, (workflow_id, user_id))

            workflow_row = cursor.fetchone()

        if not workflow_row:
            raise HTTPException(status_code=404, detail="Schedule workflow not found")

        # Register with scheduler
        from workflow_scheduler import get_scheduler
        scheduler = get_scheduler()
        scheduler.register_workflow(dict(workflow_row))

        logger.info(f"Registered schedule workflow {workflow_id}")

        return {
            "success": True,
            "workflow_id": workflow_id,
            "message": "Workflow registered with scheduler"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error registering schedule: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/workflows/scheduled-jobs")
async def list_scheduled_jobs(token_data: dict = Depends(get_current_user_from_token)):
    """
    Get list of all scheduled jobs

    Args:
        token_data: User authentication

    Returns:
        List of scheduled jobs
    """
    try:
        from workflow_scheduler import get_scheduler
        scheduler = get_scheduler()

        jobs = scheduler.get_scheduled_jobs()

        return {
            "jobs": jobs,
            "count": len(jobs)
        }

    except Exception as e:
        logger.error(f"Error listing scheduled jobs: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# INTEGRATIONS ENDPOINTS
# ============================================

@app.get("/api/integrations", response_model=List[IntegrationInfo])
async def list_integrations(token_data: dict = Depends(get_current_user_from_token)):
    """
    List all available integrations with connection status

    Returns list of integrations (Gmail, Google Drive, Telegram) with:
    - Connection status (connected/disconnected/error)
    - Last sync time if connected
    """
    try:
        user_id = token_data['user_id']
        db = get_db()

        # Define available integrations
        integrations = [
            {
                'type': 'gmail',
                'name': 'Gmail',
                'description': 'Send and receive emails via Gmail API',
                'icon': 'mail',
                'requires_oauth': True,
                'status': 'disconnected',
                'last_sync': None
            },
            {
                'type': 'google_drive',
                'name': 'Google Drive',
                'description': 'Upload and manage files in Google Drive',
                'icon': 'hard-drive',
                'requires_oauth': True,
                'status': 'disconnected',
                'last_sync': None
            },
            {
                'type': 'telegram',
                'name': 'Telegram',
                'description': 'Send messages via Telegram bot',
                'icon': 'message-circle',
                'requires_oauth': False,
                'status': 'disconnected',
                'last_sync': None
            }
        ]

        # Check connection status for each integration
        for integration in integrations:
            token = db.get_integration_token(user_id, integration['type'])
            if token:
                integration['status'] = 'connected'
                integration['last_sync'] = token.get('updated_at')

        logger.info(f"Listed {len(integrations)} integrations for user {user_id}")
        return integrations

    except Exception as e:
        logger.error(f"Error listing integrations: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/integrations/connect")
async def connect_integration(
    request: ConnectRequest,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    Initiate connection to an integration

    For Gmail/Google Drive: Returns OAuth URL for user authorization
    For Telegram: Saves bot token directly
    """
    try:
        user_id = token_data['user_id']
        integration_type = request.integration_type

        # Validate integration type
        if integration_type not in ['gmail', 'google_drive', 'telegram']:
            raise HTTPException(status_code=400, detail="Invalid integration type")

        # Handle Telegram (direct bot token)
        if integration_type == 'telegram':
            if not request.bot_token:
                raise HTTPException(status_code=400, detail="bot_token required for Telegram")

            db = get_db()
            # Save token (expires in 1 year)
            expires_at = (datetime.now() + timedelta(days=365)).isoformat()

            # Prepare metadata with chat_id if provided
            metadata = {}
            if request.chat_id:
                metadata['chat_id'] = request.chat_id

            db.save_integration_token(
                user_id=user_id,
                integration_type='telegram',
                access_token=request.bot_token,
                refresh_token='',
                expires_at=expires_at,
                metadata=metadata if metadata else None
            )

            logger.info(f"Connected Telegram integration for user {user_id}")
            return {"success": True, "message": "Telegram bot connected successfully"}

        # Handle OAuth integrations (Gmail, Google Drive)
        else:
            # Get OAuth configuration from environment
            client_id = os.getenv('GOOGLE_CLIENT_ID')
            redirect_uri = os.getenv('GOOGLE_REDIRECT_URI')

            if not client_id or not redirect_uri:
                raise HTTPException(
                    status_code=500,
                    detail="Google OAuth not configured. Please set GOOGLE_CLIENT_ID and GOOGLE_REDIRECT_URI environment variables."
                )

            # Scopes based on integration type
            if integration_type == 'gmail':
                scopes = [
                    'https://www.googleapis.com/auth/gmail.send',
                    'https://www.googleapis.com/auth/gmail.readonly'
                ]
                scope_param = 'https://www.googleapis.com/auth/gmail.send https://www.googleapis.com/auth/gmail.readonly'
            else:  # google_drive
                scopes = ['https://www.googleapis.com/auth/drive.file']
                scope_param = 'https://www.googleapis.com/auth/drive.file'

            # Generate state with user_id and integration_type
            # Format: "user_id:integration_type"
            state = f"{user_id}:{integration_type}"

            # Build OAuth URL
            from urllib.parse import urlencode
            params = {
                'client_id': client_id,
                'redirect_uri': redirect_uri,
                'response_type': 'code',
                'scope': scope_param,
                'state': state,
                'access_type': 'offline',
                'prompt': 'consent'  # Force consent to get refresh token
            }
            oauth_url = f"https://accounts.google.com/o/oauth2/v2/auth?{urlencode(params)}"

            logger.info(f"Generated OAuth URL for {integration_type} for user {user_id}")
            return {
                "oauth_url": oauth_url,
                "state": state,
                "message": "Please authorize the application"
            }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error connecting integration: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/integrations/callback")
async def oauth_callback(code: str, state: str):
    """
    OAuth callback handler

    Exchanges authorization code for access/refresh tokens
    and saves them to the database
    """
    from google.oauth2.credentials import Credentials
    from google_auth_oauthlib.flow import Flow
    import json as json_lib

    try:
        logger.info(f"OAuth callback received: code={code[:20]}..., state={state[:20]}...")

        # Get OAuth config from environment
        client_id = os.getenv('GOOGLE_CLIENT_ID')
        client_secret = os.getenv('GOOGLE_CLIENT_SECRET')
        redirect_uri = os.getenv('GOOGLE_REDIRECT_URI')

        if not all([client_id, client_secret, redirect_uri]):
            logger.error("Missing Google OAuth configuration")
            return RedirectResponse(
                url="/integrations?error=oauth_config_missing",
                status_code=302
            )

        # Parse state to get user_id and integration_type
        # Format: "user_id:integration_type"
        try:
            user_id_str, integration_type = state.split(':')
            user_id = int(user_id_str)
        except (ValueError, AttributeError):
            logger.error(f"Invalid state parameter: {state}")
            return RedirectResponse(
                url="/integrations?error=invalid_state",
                status_code=302
            )

        # Create OAuth flow
        client_config = {
            "web": {
                "client_id": client_id,
                "client_secret": client_secret,
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token",
                "redirect_uris": [redirect_uri]
            }
        }

        # Determine scopes based on integration type
        if integration_type == 'gmail':
            scopes = [
                'https://www.googleapis.com/auth/gmail.send',
                'https://www.googleapis.com/auth/gmail.readonly'
            ]
        elif integration_type == 'google_drive':
            scopes = ['https://www.googleapis.com/auth/drive.file']
        else:
            logger.error(f"Unknown integration type: {integration_type}")
            return RedirectResponse(
                url="/integrations?error=unknown_integration",
                status_code=302
            )

        flow = Flow.from_client_config(
            client_config,
            scopes=scopes,
            redirect_uri=redirect_uri
        )

        # Exchange authorization code for tokens
        flow.fetch_token(code=code)
        credentials = flow.credentials

        # Save tokens to database
        db = get_db()

        # Calculate expiry
        from datetime import datetime, timedelta
        if credentials.expiry:
            expires_at = credentials.expiry.isoformat()
        else:
            # Default to 1 hour
            expires_at = (datetime.now() + timedelta(hours=1)).isoformat()

        db.save_integration_token(
            user_id=user_id,
            integration_type=integration_type,
            access_token=credentials.token,
            refresh_token=credentials.refresh_token or '',
            expires_at=expires_at
        )

        logger.info(f"Successfully saved {integration_type} tokens for user {user_id}")

        # Redirect to frontend with success
        return RedirectResponse(
            url=f"/integrations?success={integration_type}",
            status_code=302
        )

    except Exception as e:
        logger.error(f"Error in OAuth callback: {e}")
        import traceback
        traceback.print_exc()
        return RedirectResponse(
            url=f"/integrations?error=oauth_failed",
            status_code=302
        )


@app.post("/api/integrations/disconnect")
async def disconnect_integration(
    integration_type: str,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    Disconnect an integration

    Removes stored tokens for the specified integration
    """
    try:
        user_id = token_data['user_id']

        # Validate integration type
        if integration_type not in ['gmail', 'google_drive', 'telegram']:
            raise HTTPException(status_code=400, detail="Invalid integration type")

        db = get_db()
        success = db.delete_integration_token(user_id, integration_type)

        if success:
            logger.info(f"Disconnected {integration_type} for user {user_id}")
            return {
                "success": True,
                "message": f"{integration_type} disconnected successfully"
            }
        else:
            raise HTTPException(status_code=404, detail="Integration not found")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error disconnecting integration: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/integrations/test")
async def test_integration(
    integration_type: str,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    Test an integration connection

    Attempts to connect to the service and make a simple API call
    to verify the connection works
    """
    try:
        user_id = token_data['user_id']

        # Validate integration type
        if integration_type not in ['gmail', 'google_drive', 'telegram']:
            raise HTTPException(status_code=400, detail="Invalid integration type")

        db = get_db()
        token = db.get_integration_token(user_id, integration_type)

        if not token:
            raise HTTPException(status_code=404, detail="Integration not connected")

        # Try to connect using MCP client
        from agents.mcp_client import MCPClient

        client = MCPClient()

        # Test connection based on integration type
        if integration_type == 'telegram':
            # For Telegram, test with bot token
            try:
                client.connect('telegram', {'bot_token': token['access_token']})
                logger.info(f"Telegram integration test successful for user {user_id}")
                return {
                    "success": True,
                    "message": "Telegram bot connection successful",
                    "integration_type": integration_type
                }
            except Exception as e:
                logger.error(f"Telegram test failed: {e}")
                return {
                    "success": False,
                    "message": f"Connection failed: {str(e)}",
                    "integration_type": integration_type
                }
        else:
            # For Google services, would need full OAuth token
            # For MVP, return simulation
            logger.info(f"{integration_type} test simulated for user {user_id}")
            return {
                "success": True,
                "message": f"{integration_type} connection test simulated (OAuth required for full test)",
                "integration_type": integration_type,
                "note": "In production, this would make a real API call to verify the connection"
            }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error testing integration: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# DASHBOARD ENDPOINTS
# ============================================

class DashboardStats(BaseModel):
    """Dashboard statistics response"""
    total_projects: int
    active_workflows: int
    connected_integrations: int
    ai_requests_today: int
    ai_requests_week: int
    total_databases: int
    total_records: int


class ActivityItem(BaseModel):
    """Activity feed item"""
    id: int
    type: str  # 'project_created', 'workflow_executed', 'integration_connected', 'ai_request', etc.
    title: str
    description: str
    timestamp: str
    icon: str  # Icon name for frontend


@app.get("/api/dashboard/stats", response_model=DashboardStats)
async def get_dashboard_stats(token_data: dict = Depends(get_current_user_from_token)):
    """
    Get dashboard statistics

    Returns counts for:
    - Total projects
    - Active workflows (enabled)
    - Connected integrations
    - AI requests (today and week)
    - Total databases
    - Total records
    """
    try:
        user_id = token_data['user_id']
        db = get_db()

        with sqlite3.connect(db.db_path) as conn:
            # Count projects
            cursor = conn.execute(
                "SELECT COUNT(*) FROM projects WHERE user_id = ?",
                (user_id,)
            )
            total_projects = cursor.fetchone()[0]

            # Count active workflows
            cursor = conn.execute(
                "SELECT COUNT(*) FROM workflows WHERE user_id = ? AND enabled = 1",
                (user_id,)
            )
            active_workflows = cursor.fetchone()[0]

            # Count connected integrations
            cursor = conn.execute(
                "SELECT COUNT(*) FROM integration_tokens WHERE user_id = ?",
                (user_id,)
            )
            connected_integrations = cursor.fetchone()[0]

            # Count AI requests today
            today = datetime.now().date().isoformat()
            cursor = conn.execute(
                """SELECT COUNT(*) FROM requests
                   WHERE (user_id = ? OR user_id IS NULL) AND date(timestamp) = date(?)""",
                (user_id, today)
            )
            ai_requests_today = cursor.fetchone()[0]

            # Count AI requests this week
            week_ago = (datetime.now() - timedelta(days=7)).isoformat()
            cursor = conn.execute(
                """SELECT COUNT(*) FROM requests
                   WHERE (user_id = ? OR user_id IS NULL) AND timestamp >= ?""",
                (user_id, week_ago)
            )
            ai_requests_week = cursor.fetchone()[0]

            # Count total databases
            cursor = conn.execute(
                """SELECT COUNT(*) FROM databases d
                   JOIN projects p ON d.project_id = p.id
                   WHERE p.user_id = ?""",
                (user_id,)
            )
            total_databases = cursor.fetchone()[0]

            # Count total records across all databases
            cursor = conn.execute(
                """SELECT COUNT(*) FROM database_records
                   WHERE database_id IN (
                       SELECT d.id FROM databases d
                       JOIN projects p ON d.project_id = p.id
                       WHERE p.user_id = ?
                   )""",
                (user_id,)
            )
            total_records = cursor.fetchone()[0]

        return DashboardStats(
            total_projects=total_projects,
            active_workflows=active_workflows,
            connected_integrations=connected_integrations,
            ai_requests_today=ai_requests_today,
            ai_requests_week=ai_requests_week,
            total_databases=total_databases,
            total_records=total_records
        )

    except Exception as e:
        logger.error(f"Error fetching dashboard stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/dashboard/activity", response_model=List[ActivityItem])
async def get_dashboard_activity(
    limit: int = 20,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    Get recent activity feed

    Returns recent actions across all modules:
    - Projects created
    - Workflows executed
    - Integrations connected
    - AI requests made
    - Records created

    Sorted by most recent first, limited to 20 items by default
    """
    try:
        user_id = token_data['user_id']
        db = get_db()

        activities = []

        with sqlite3.connect(db.db_path) as conn:
            # Get recent projects (last 30 days)
            thirty_days_ago = (datetime.now() - timedelta(days=30)).isoformat()
            cursor = conn.execute(
                """SELECT id, name, created_at FROM projects
                   WHERE user_id = ? AND created_at >= ?
                   ORDER BY created_at DESC LIMIT 5""",
                (user_id, thirty_days_ago)
            )
            for row in cursor.fetchall():
                activities.append({
                    'id': row[0],
                    'type': 'project_created',
                    'title': f"Created project: {row[1]}",
                    'description': 'New project created',
                    'timestamp': row[2],
                    'icon': 'Folder'
                })

            # Get recent workflow executions
            cursor = conn.execute(
                """SELECT we.id, w.name, we.executed_at
                   FROM workflow_executions we
                   JOIN workflows w ON we.workflow_id = w.id
                   WHERE w.user_id = ?
                   ORDER BY we.executed_at DESC LIMIT 10""",
                (user_id,)
            )
            for row in cursor.fetchall():
                activities.append({
                    'id': row[0],
                    'type': 'workflow_executed',
                    'title': f"Executed workflow: {row[1]}",
                    'description': 'Workflow ran successfully',
                    'timestamp': row[2],
                    'icon': 'Zap'
                })

            # Get recent integrations
            cursor = conn.execute(
                """SELECT id, integration_type, created_at FROM integration_tokens
                   WHERE user_id = ?
                   ORDER BY created_at DESC LIMIT 5""",
                (user_id,)
            )
            for row in cursor.fetchall():
                integration_name = row[1].replace('_', ' ').title()
                activities.append({
                    'id': row[0],
                    'type': 'integration_connected',
                    'title': f"Connected {integration_name}",
                    'description': 'New integration added',
                    'timestamp': row[2],
                    'icon': 'Plug'
                })

            # Get recent AI requests
            cursor = conn.execute(
                """SELECT id, prompt, timestamp FROM requests
                   WHERE (user_id = ? OR user_id IS NULL)
                   ORDER BY timestamp DESC LIMIT 10""",
                (user_id,)
            )
            for row in cursor.fetchall():
                prompt_preview = row[1][:50] + '...' if len(row[1]) > 50 else row[1]
                activities.append({
                    'id': row[0],
                    'type': 'ai_request',
                    'title': f"AI Request: {prompt_preview}",
                    'description': 'Queried AI model',
                    'timestamp': row[2],
                    'icon': 'MessageSquare'
                })

        # Sort all activities by timestamp (most recent first)
        activities.sort(key=lambda x: x['timestamp'], reverse=True)

        # Limit to requested number
        activities = activities[:limit]

        return activities

    except Exception as e:
        logger.error(f"Error fetching dashboard activity: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/dashboard/charts/ai-requests")
async def get_ai_requests_chart(
    days: int = 7,
    token_data: dict = Depends(get_current_user_from_token)
):
    """
    Get AI requests over time for charts

    Returns daily counts for the last N days (default 7)
    """
    try:
        user_id = token_data['user_id']
        db = get_db()

        data = []

        with sqlite3.connect(db.db_path) as conn:
            # Get requests grouped by date
            start_date = (datetime.now() - timedelta(days=days)).date().isoformat()
            cursor = conn.execute(
                """SELECT date(timestamp) as day, COUNT(*) as count
                   FROM requests
                   WHERE (user_id = ? OR user_id IS NULL) AND date(timestamp) >= date(?)
                   GROUP BY date(timestamp)
                   ORDER BY date(timestamp)""",
                (user_id, start_date)
            )

            for row in cursor.fetchall():
                data.append({
                    'date': row[0],
                    'requests': row[1]
                })

        return {"data": data}

    except Exception as e:
        logger.error(f"Error fetching AI requests chart data: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/dashboard/charts/model-usage")
async def get_model_usage_chart(token_data: dict = Depends(get_current_user_from_token)):
    """
    Get model usage distribution for pie chart

    Returns count of requests per model
    """
    try:
        user_id = token_data['user_id']
        db = get_db()

        data = []

        with sqlite3.connect(db.db_path) as conn:
            # Get requests grouped by model
            cursor = conn.execute(
                """SELECT model, COUNT(*) as count
                   FROM requests
                   WHERE (user_id = ? OR user_id IS NULL)
                   GROUP BY model
                   ORDER BY count DESC""",
                (user_id,)
            )

            for row in cursor.fetchall():
                data.append({
                    'model': row[0] or 'Unknown',
                    'requests': row[1]
                })

        return {"data": data}

    except Exception as e:
        logger.error(f"Error fetching model usage chart data: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/dashboard/charts/workflow-stats")
async def get_workflow_stats_chart(token_data: dict = Depends(get_current_user_from_token)):
    """
    Get workflow execution statistics for bar chart

    Returns execution counts per workflow
    """
    try:
        user_id = token_data['user_id']
        db = get_db()

        data = []

        with sqlite3.connect(db.db_path) as conn:
            # Get execution counts per workflow
            cursor = conn.execute(
                """SELECT w.name, COUNT(we.id) as count
                   FROM workflows w
                   LEFT JOIN workflow_executions we ON w.id = we.workflow_id
                   WHERE w.user_id = ?
                   GROUP BY w.id, w.name
                   ORDER BY count DESC
                   LIMIT 10""",
                (user_id,)
            )

            for row in cursor.fetchall():
                data.append({
                    'workflow': row[0],
                    'executions': row[1]
                })

        return {"data": data}

    except Exception as e:
        logger.error(f"Error fetching workflow stats chart data: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
# ============================================

if __name__ == "__main__":
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (–¥–ª—è Railway/Vercel) –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º 8000 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    port = int(os.getenv("PORT", 8000))
    
    print("üöÄ Starting AI Development System API Server...")
    print(f"üìö API Documentation: http://localhost:{port}/docs")
    print(f"üîç Health Check: http://localhost:{port}/api/health")
    print(f"üåê Server running on: http://0.0.0.0:{port}")
    print("")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=port,
        log_level="info"
    )
